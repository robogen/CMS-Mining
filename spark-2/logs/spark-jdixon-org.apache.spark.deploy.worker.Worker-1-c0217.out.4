Spark Command: /usr/lib/jvm/java-1.7.0-openjdk-1.7.0.131.x86_64/jre/bin/java -cp /lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/conf/:/lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/jars/* -Xmx1g -XX:MaxPermSize=256m org.apache.spark.deploy.worker.Worker --webui-port 8081 spark://c0217.crane.hcc.unl.edu:7077
========================================
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
17/04/26 10:48:44 INFO Worker: Started daemon with process name: 29940@c1907.crane.hcc.unl.edu
17/04/26 10:48:44 INFO SignalUtils: Registered signal handler for TERM
17/04/26 10:48:44 INFO SignalUtils: Registered signal handler for HUP
17/04/26 10:48:44 INFO SignalUtils: Registered signal handler for INT
17/04/26 10:48:44 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/04/26 10:48:44 INFO SecurityManager: Changing view acls to: jdixon
17/04/26 10:48:44 INFO SecurityManager: Changing modify acls to: jdixon
17/04/26 10:48:44 INFO SecurityManager: Changing view acls groups to: 
17/04/26 10:48:44 INFO SecurityManager: Changing modify acls groups to: 
17/04/26 10:48:44 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(jdixon); groups with view permissions: Set(); users  with modify permissions: Set(jdixon); groups with modify permissions: Set()
17/04/26 10:48:45 INFO Utils: Successfully started service 'sparkWorker' on port 43469.
17/04/26 10:48:45 INFO Worker: Starting Spark worker 10.138.19.7:43469 with 16 cores, 61.8 GB RAM
17/04/26 10:48:45 INFO Worker: Running Spark version 2.1.0
17/04/26 10:48:45 INFO Worker: Spark home: /lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2
17/04/26 10:48:45 INFO Utils: Successfully started service 'WorkerUI' on port 8081.
17/04/26 10:48:46 INFO WorkerWebUI: Bound WorkerWebUI to 0.0.0.0, and started at http://10.138.19.7:8081
17/04/26 10:48:46 INFO Worker: Connecting to master c0217.crane.hcc.unl.edu:7077...
17/04/26 10:48:46 WARN Worker: Failed to connect to master c0217.crane.hcc.unl.edu:7077
org.apache.spark.SparkException: Exception thrown in awaitResult
	at org.apache.spark.rpc.RpcTimeout$$anonfun$1.applyOrElse(RpcTimeout.scala:77)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$1.applyOrElse(RpcTimeout.scala:75)
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:59)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:59)
	at scala.PartialFunction$OrElse.apply(PartialFunction.scala:167)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:83)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:100)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:108)
	at org.apache.spark.deploy.worker.Worker$$anonfun$org$apache$spark$deploy$worker$Worker$$tryRegisterAllMasters$1$$anon$1.run(Worker.scala:218)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:473)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.io.IOException: Failed to connect to c0217.crane.hcc.unl.edu/10.138.2.17:7077
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:228)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:179)
	at org.apache.spark.rpc.netty.NettyRpcEnv.createClient(NettyRpcEnv.scala:197)
	at org.apache.spark.rpc.netty.Outbox$$anon$1.call(Outbox.scala:191)
	at org.apache.spark.rpc.netty.Outbox$$anon$1.call(Outbox.scala:187)
	... 4 more
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: c0217.crane.hcc.unl.edu/10.138.2.17:7077
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:257)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:291)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:640)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:575)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:489)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:451)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:140)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	... 1 more
17/04/26 10:48:53 INFO Worker: Retrying connection to master (attempt # 1)
17/04/26 10:48:53 INFO Worker: Connecting to master c0217.crane.hcc.unl.edu:7077...
17/04/26 10:48:53 INFO TransportClientFactory: Successfully created connection to c0217.crane.hcc.unl.edu/10.138.2.17:7077 after 1 ms (0 ms spent in bootstraps)
17/04/26 10:48:53 INFO Worker: Successfully registered with master spark://c0217.crane.hcc.unl.edu:7077
17/04/26 10:49:59 INFO Worker: Asked to launch executor app-20170426104959-0000/0 for es_scatter.py
17/04/26 10:49:59 INFO SecurityManager: Changing view acls to: jdixon
17/04/26 10:49:59 INFO SecurityManager: Changing modify acls to: jdixon
17/04/26 10:49:59 INFO SecurityManager: Changing view acls groups to: 
17/04/26 10:49:59 INFO SecurityManager: Changing modify acls groups to: 
17/04/26 10:49:59 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(jdixon); groups with view permissions: Set(); users  with modify permissions: Set(jdixon); groups with modify permissions: Set()
17/04/26 10:49:59 INFO ExecutorRunner: Launch command: "/usr/lib/jvm/java-1.7.0-openjdk-1.7.0.131.x86_64/jre/bin/java" "-cp" "/lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/conf/:/lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/jars/*" "-Xmx2048M" "-Dspark.driver.port=37097" "-XX:MaxPermSize=256m" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@10.138.2.17:37097" "--executor-id" "0" "--hostname" "10.138.19.7" "--cores" "3" "--app-id" "app-20170426104959-0000" "--worker-url" "spark://Worker@10.138.19.7:43469"
17/04/26 10:50:12 INFO Worker: Asked to kill executor app-20170426104959-0000/0
17/04/26 10:50:12 INFO ExecutorRunner: Runner thread for executor app-20170426104959-0000/0 interrupted
17/04/26 10:50:12 INFO ExecutorRunner: Killing process!
17/04/26 10:50:13 INFO Worker: Executor app-20170426104959-0000/0 finished with state KILLED exitStatus 0
17/04/26 10:50:13 INFO Worker: Cleaning up local directories for application app-20170426104959-0000
17/04/26 10:50:13 INFO ExternalShuffleBlockResolver: Application app-20170426104959-0000 removed, cleanupLocalDirs = true
