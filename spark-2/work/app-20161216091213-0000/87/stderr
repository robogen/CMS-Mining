16/12/16 09:13:55 INFO CoarseGrainedExecutorBackend: Started daemon with process name: 130180@c0120.crane.hcc.unl.edu
16/12/16 09:13:55 INFO SignalUtils: Registered signal handler for TERM
16/12/16 09:13:55 INFO SignalUtils: Registered signal handler for HUP
16/12/16 09:13:55 INFO SignalUtils: Registered signal handler for INT
16/12/16 09:13:55 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
16/12/16 09:13:56 INFO SecurityManager: Changing view acls to: jdixon
16/12/16 09:13:56 INFO SecurityManager: Changing modify acls to: jdixon
16/12/16 09:13:56 INFO SecurityManager: Changing view acls groups to: 
16/12/16 09:13:56 INFO SecurityManager: Changing modify acls groups to: 
16/12/16 09:13:56 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(jdixon); groups with view permissions: Set(); users  with modify permissions: Set(jdixon); groups with modify permissions: Set()
Exception in thread "main" java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:714)
	at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:949)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1360)
	at org.apache.spark.rpc.netty.Dispatcher$$anonfun$1.apply$mcVI$sp(Dispatcher.scala:196)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)
	at org.apache.spark.rpc.netty.Dispatcher.<init>(Dispatcher.scala:195)
	at org.apache.spark.rpc.netty.NettyRpcEnv.<init>(NettyRpcEnv.scala:54)
	at org.apache.spark.rpc.netty.NettyRpcEnvFactory.create(NettyRpcEnv.scala:444)
	at org.apache.spark.rpc.RpcEnv$.create(RpcEnv.scala:44)
	at org.apache.spark.executor.CoarseGrainedExecutorBackend$$anonfun$run$1.apply$mcV$sp(CoarseGrainedExecutorBackend.scala:181)
	at org.apache.spark.deploy.SparkHadoopUtil$$anon$1.run(SparkHadoopUtil.scala:71)
	at org.apache.spark.deploy.SparkHadoopUtil$$anon$1.run(SparkHadoopUtil.scala:70)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.spark.deploy.SparkHadoopUtil.runAsSparkUser(SparkHadoopUtil.scala:70)
	at org.apache.spark.executor.CoarseGrainedExecutorBackend$.run(CoarseGrainedExecutorBackend.scala:174)
	at org.apache.spark.executor.CoarseGrainedExecutorBackend$.main(CoarseGrainedExecutorBackend.scala:270)
	at org.apache.spark.executor.CoarseGrainedExecutorBackend.main(CoarseGrainedExecutorBackend.scala)
