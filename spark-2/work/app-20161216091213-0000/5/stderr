16/12/16 09:13:35 INFO CoarseGrainedExecutorBackend: Started daemon with process name: 128186@c0120.crane.hcc.unl.edu
16/12/16 09:13:35 INFO SignalUtils: Registered signal handler for TERM
16/12/16 09:13:35 INFO SignalUtils: Registered signal handler for HUP
16/12/16 09:13:35 INFO SignalUtils: Registered signal handler for INT
16/12/16 09:13:36 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
16/12/16 09:13:36 INFO SecurityManager: Changing view acls to: jdixon
16/12/16 09:13:36 INFO SecurityManager: Changing modify acls to: jdixon
16/12/16 09:13:36 INFO SecurityManager: Changing view acls groups to: 
16/12/16 09:13:36 INFO SecurityManager: Changing modify acls groups to: 
16/12/16 09:13:36 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(jdixon); groups with view permissions: Set(); users  with modify permissions: Set(jdixon); groups with modify permissions: Set()
16/12/16 09:13:40 WARN ThreadLocalRandom: Failed to generate a seed from SecureRandom within 3 seconds. Not enough entrophy?
16/12/16 09:13:40 INFO TransportClientFactory: Successfully created connection to /10.138.1.20:43230 after 3189 ms (0 ms spent in bootstraps)
16/12/16 09:13:40 INFO SecurityManager: Changing view acls to: jdixon
16/12/16 09:13:40 INFO SecurityManager: Changing modify acls to: jdixon
16/12/16 09:13:40 INFO SecurityManager: Changing view acls groups to: 
16/12/16 09:13:40 INFO SecurityManager: Changing modify acls groups to: 
16/12/16 09:13:40 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(jdixon); groups with view permissions: Set(); users  with modify permissions: Set(jdixon); groups with modify permissions: Set()
16/12/16 09:13:40 INFO TransportClientFactory: Successfully created connection to /10.138.1.20:43230 after 1 ms (0 ms spent in bootstraps)
16/12/16 09:13:40 INFO DiskBlockManager: Created local directory at /tmp/spark-b5a73ab3-5994-4668-8396-d9245dd0b4a1/executor-3c4ff3ec-0ef0-4a3b-a9cd-d4646cb32439/blockmgr-7f19c43a-eb17-44de-98eb-07810bd24893
16/12/16 09:13:40 INFO MemoryStore: MemoryStore started with capacity 397.5 MB
16/12/16 09:13:41 INFO CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@10.138.1.20:43230
16/12/16 09:13:41 INFO WorkerWatcher: Connecting to worker spark://Worker@10.138.1.20:43494
16/12/16 09:13:41 INFO TransportClientFactory: Successfully created connection to /10.138.1.20:43494 after 1 ms (0 ms spent in bootstraps)
16/12/16 09:13:41 INFO WorkerWatcher: Successfully connected to spark://Worker@10.138.1.20:43494
16/12/16 09:13:41 INFO CoarseGrainedExecutorBackend: Successfully registered with driver
16/12/16 09:13:41 INFO Executor: Starting executor ID 5 on host 10.138.1.20
16/12/16 09:13:41 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43213.
16/12/16 09:13:41 INFO NettyBlockTransferService: Server created on 10.138.1.20:43213
16/12/16 09:13:41 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(5, 10.138.1.20, 43213)
16/12/16 09:13:41 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(5, 10.138.1.20, 43213)
16/12/16 09:13:45 INFO CoarseGrainedExecutorBackend: Got assigned task 209
16/12/16 09:13:45 INFO CoarseGrainedExecutorBackend: Got assigned task 211
16/12/16 09:13:45 INFO Executor: Running task 21.0 in stage 20.0 (TID 209)
16/12/16 09:13:45 INFO Executor: Running task 26.0 in stage 20.0 (TID 211)
16/12/16 09:13:46 INFO Executor: Fetching spark://10.138.1.20:43230/files/es_sparklocal.py with timestamp 1481901132724
16/12/16 09:13:46 INFO TransportClientFactory: Successfully created connection to /10.138.1.20:43230 after 21 ms (0 ms spent in bootstraps)
16/12/16 09:13:46 INFO Utils: Fetching spark://10.138.1.20:43230/files/es_sparklocal.py to /tmp/spark-b5a73ab3-5994-4668-8396-d9245dd0b4a1/executor-3c4ff3ec-0ef0-4a3b-a9cd-d4646cb32439/spark-bf6e3fd7-cabd-4e6e-bea2-5c9d92bac6e2/fetchFileTemp4504103344591263787.tmp
16/12/16 09:13:46 INFO Utils: Copying /tmp/spark-b5a73ab3-5994-4668-8396-d9245dd0b4a1/executor-3c4ff3ec-0ef0-4a3b-a9cd-d4646cb32439/spark-bf6e3fd7-cabd-4e6e-bea2-5c9d92bac6e2/17287905961481901132724_cache to /lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/work/app-20161216091213-0000/5/./es_sparklocal.py
16/12/16 09:13:46 INFO Executor: Fetching spark://10.138.1.20:43230/jars/elasticsearch-hadoop-6.0.0.BUILD.SNAPSHOT.jar with timestamp 1481901132133
16/12/16 09:13:46 INFO Utils: Fetching spark://10.138.1.20:43230/jars/elasticsearch-hadoop-6.0.0.BUILD.SNAPSHOT.jar to /tmp/spark-b5a73ab3-5994-4668-8396-d9245dd0b4a1/executor-3c4ff3ec-0ef0-4a3b-a9cd-d4646cb32439/spark-bf6e3fd7-cabd-4e6e-bea2-5c9d92bac6e2/fetchFileTemp1230691373936482165.tmp
16/12/16 09:13:46 INFO Utils: Copying /tmp/spark-b5a73ab3-5994-4668-8396-d9245dd0b4a1/executor-3c4ff3ec-0ef0-4a3b-a9cd-d4646cb32439/spark-bf6e3fd7-cabd-4e6e-bea2-5c9d92bac6e2/-8955836221481901132133_cache to /lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/work/app-20161216091213-0000/5/./elasticsearch-hadoop-6.0.0.BUILD.SNAPSHOT.jar
16/12/16 09:13:46 INFO Executor: Adding file:/lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/work/app-20161216091213-0000/5/./elasticsearch-hadoop-6.0.0.BUILD.SNAPSHOT.jar to class loader
16/12/16 09:13:46 INFO MapOutputTrackerWorker: Updating epoch to 2 and clearing cache
16/12/16 09:13:46 INFO TorrentBroadcast: Started reading broadcast variable 24
16/12/16 09:13:46 INFO TransportClientFactory: Successfully created connection to /10.138.1.20:36769 after 9 ms (0 ms spent in bootstraps)
16/12/16 09:13:46 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 6.7 KB, free 397.5 MB)
16/12/16 09:13:46 INFO TorrentBroadcast: Reading broadcast variable 24 took 163 ms
16/12/16 09:13:46 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 11.0 KB, free 397.5 MB)
16/12/16 09:13:47 INFO TransportClientFactory: Successfully created connection to /10.138.1.20:32888 after 2 ms (0 ms spent in bootstraps)
16/12/16 09:13:47 INFO HadoopRDD: Input split: file:/lustre/work/swanson/jdixon/CMS/CMS-Mining/data/atlas-latency.json:872415232+33554432
16/12/16 09:13:47 INFO TorrentBroadcast: Started reading broadcast variable 3
16/12/16 09:13:47 WARN TransportChannelHandler: Exception in connection from /10.138.1.20:32888
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:192)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:384)
	at io.netty.buffer.PooledUnsafeDirectByteBuf.setBytes(PooledUnsafeDirectByteBuf.java:313)
	at io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:881)
	at io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:242)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:119)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:511)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:468)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:382)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:354)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:111)
	at java.lang.Thread.run(Thread.java:745)
16/12/16 09:13:47 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 22.9 KB, free 397.5 MB)
16/12/16 09:13:47 INFO TorrentBroadcast: Reading broadcast variable 3 took 40 ms
16/12/16 09:13:47 ERROR TransportResponseHandler: Still have 1 requests outstanding when connection from /10.138.1.20:32888 is closed
16/12/16 09:13:47 ERROR OneForOneBlockFetcher: Failed while starting block fetches
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:192)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:384)
	at io.netty.buffer.PooledUnsafeDirectByteBuf.setBytes(PooledUnsafeDirectByteBuf.java:313)
	at io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:881)
	at io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:242)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:119)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:511)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:468)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:382)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:354)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:111)
	at java.lang.Thread.run(Thread.java:745)
16/12/16 09:13:47 INFO RetryingBlockFetcher: Retrying fetch (1/3) for 1 outstanding blocks after 5000 ms
16/12/16 09:13:47 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 291.3 KB, free 397.2 MB)
16/12/16 09:13:47 INFO deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id
16/12/16 09:13:47 INFO deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
16/12/16 09:13:47 INFO deprecation: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
16/12/16 09:13:47 INFO deprecation: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
16/12/16 09:13:47 INFO deprecation: mapred.job.id is deprecated. Instead, use mapreduce.job.id
OpenBLAS blas_thread_init: pthread_create: Resource temporarily unavailable
OpenBLAS blas_thread_init: RLIMIT_NPROC 1024 current, 1024 max
OpenBLAS blas_thread_init: pthread_create: Resource temporarily unavailable
OpenBLAS blas_thread_init: RLIMIT_NPROC 1024 current, 1024 max
OpenBLAS blas_thread_init: pthread_create: Resource temporarily unavailable
OpenBLAS blas_thread_init: RLIMIT_NPROC 1024 current, 1024 max
OpenBLAS blas_thread_init: pthread_create: Resource temporarily unavailable
OpenBLAS blas_thread_init: RLIMIT_NPROC 1024 current, 1024 max
OpenBLAS blas_thread_init: pthread_create: Resource temporarily unavailable
OpenBLAS blas_thread_init: RLIMIT_NPROC 1024 current, 1024 max
OpenBLAS blas_thread_init: pthread_create: Resource temporarily unavailable
OpenBLAS blas_thread_init: RLIMIT_NPROC 1024 current, 1024 max
16/12/16 09:13:52 INFO PythonRunner: Times: total = 4081, boot = 1507, init = 42, finish = 2532
16/12/16 09:13:52 INFO MemoryStore: Block rdd_11_26 stored as bytes in memory (estimated size 12.4 MB, free 384.8 MB)
16/12/16 09:13:52 INFO TransportClientFactory: Found inactive connection to /10.138.1.20:32888, creating a new one.
16/12/16 09:13:52 ERROR RetryingBlockFetcher: Exception while beginning fetch of 1 outstanding blocks (after 1 retries)
java.io.IOException: Failed to connect to /10.138.1.20:32888
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:228)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:179)
	at org.apache.spark.network.netty.NettyBlockTransferService$$anon$1.createAndStart(NettyBlockTransferService.scala:96)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:140)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.access$200(RetryingBlockFetcher.java:43)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher$1.run(RetryingBlockFetcher.java:170)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused: /10.138.1.20:32888
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:224)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:289)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:528)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:468)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:382)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:354)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:111)
	... 1 more
16/12/16 09:13:52 INFO RetryingBlockFetcher: Retrying fetch (2/3) for 1 outstanding blocks after 5000 ms
16/12/16 09:13:52 INFO PythonRunner: Times: total = 431, boot = -54, init = 57, finish = 428
16/12/16 09:13:52 INFO Executor: Finished task 26.0 in stage 20.0 (TID 211). 4721 bytes result sent to driver
16/12/16 09:13:52 INFO CoarseGrainedExecutorBackend: Got assigned task 230
16/12/16 09:13:52 INFO Executor: Running task 10.2 in stage 20.0 (TID 230)
16/12/16 09:13:52 INFO HadoopRDD: Input split: file:/lustre/work/swanson/jdixon/CMS/CMS-Mining/data/atlas-latency.json:335544320+33554432
16/12/16 09:13:55 INFO PythonRunner: Times: total = 2412, boot = -73, init = 85, finish = 2400
16/12/16 09:13:55 INFO MemoryStore: Block rdd_11_10 stored as bytes in memory (estimated size 12.4 MB, free 372.4 MB)
16/12/16 09:13:55 INFO PythonRunner: Times: total = 441, boot = -45, init = 48, finish = 438
16/12/16 09:13:55 INFO Executor: Finished task 10.2 in stage 20.0 (TID 230). 4227 bytes result sent to driver
16/12/16 09:13:55 INFO CoarseGrainedExecutorBackend: Got assigned task 233
16/12/16 09:13:55 INFO Executor: Running task 22.2 in stage 20.0 (TID 233)
16/12/16 09:13:55 INFO HadoopRDD: Input split: file:/lustre/work/swanson/jdixon/CMS/CMS-Mining/data/atlas-latency.json:738197504+33554432
16/12/16 09:13:55 WARN BlockManager: Putting block rdd_11_22 failed due to an exception
16/12/16 09:13:55 WARN BlockManager: Block rdd_11_22 could not be removed as it was not found on disk or in memory
16/12/16 09:13:55 ERROR Executor: Exception in task 22.2 in stage 20.0 (TID 233)
java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:714)
	at org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:147)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:332)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:330)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:951)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:926)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:866)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:926)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:670)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:330)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:281)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70)
	at org.apache.spark.scheduler.Task.run(Task.scala:86)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
16/12/16 09:13:55 ERROR SparkUncaughtExceptionHandler: Uncaught exception in thread Thread[Executor task launch worker-1,5,main]
java.lang.OutOfMemoryError: unable to create new native thread
	at java.lang.Thread.start0(Native Method)
	at java.lang.Thread.start(Thread.java:714)
	at org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:147)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:332)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:330)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:951)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:926)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:866)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:926)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:670)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:330)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:281)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70)
	at org.apache.spark.scheduler.Task.run(Task.scala:86)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
