Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
17/05/11 23:25:08 INFO CoarseGrainedExecutorBackend: Started daemon with process name: 140316@c1011.crane.hcc.unl.edu
17/05/11 23:25:08 INFO SignalUtils: Registered signal handler for TERM
17/05/11 23:25:08 INFO SignalUtils: Registered signal handler for HUP
17/05/11 23:25:08 INFO SignalUtils: Registered signal handler for INT
17/05/11 23:25:09 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/05/11 23:25:09 INFO SecurityManager: Changing view acls to: jdixon
17/05/11 23:25:09 INFO SecurityManager: Changing modify acls to: jdixon
17/05/11 23:25:09 INFO SecurityManager: Changing view acls groups to: 
17/05/11 23:25:09 INFO SecurityManager: Changing modify acls groups to: 
17/05/11 23:25:09 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(jdixon); groups with view permissions: Set(); users  with modify permissions: Set(jdixon); groups with modify permissions: Set()
17/05/11 23:25:10 INFO TransportClientFactory: Successfully created connection to /10.138.10.6:36674 after 165 ms (0 ms spent in bootstraps)
17/05/11 23:25:10 INFO SecurityManager: Changing view acls to: jdixon
17/05/11 23:25:10 INFO SecurityManager: Changing modify acls to: jdixon
17/05/11 23:25:10 INFO SecurityManager: Changing view acls groups to: 
17/05/11 23:25:10 INFO SecurityManager: Changing modify acls groups to: 
17/05/11 23:25:10 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(jdixon); groups with view permissions: Set(); users  with modify permissions: Set(jdixon); groups with modify permissions: Set()
17/05/11 23:25:10 INFO TransportClientFactory: Successfully created connection to /10.138.10.6:36674 after 2 ms (0 ms spent in bootstraps)
17/05/11 23:25:11 INFO DiskBlockManager: Created local directory at /lustre/work/swanson/jdixon/tmp/spark-4186fe0a-9cd5-4dbb-9b2c-44e7ae932b75/executor-eef2a49b-f0df-4f89-8a9b-3079f70613da/blockmgr-62d8e611-ede3-4462-af2a-48f07b28481f
17/05/11 23:25:11 INFO MemoryStore: MemoryStore started with capacity 912.3 MB
17/05/11 23:25:11 INFO CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@10.138.10.6:36674
17/05/11 23:25:11 INFO WorkerWatcher: Connecting to worker spark://Worker@10.138.10.11:38625
17/05/11 23:25:11 INFO TransportClientFactory: Successfully created connection to /10.138.10.11:38625 after 3 ms (0 ms spent in bootstraps)
17/05/11 23:25:11 INFO WorkerWatcher: Successfully connected to spark://Worker@10.138.10.11:38625
17/05/11 23:25:11 INFO CoarseGrainedExecutorBackend: Successfully registered with driver
17/05/11 23:25:11 INFO Executor: Starting executor ID 0 on host 10.138.10.11
17/05/11 23:25:11 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 41411.
17/05/11 23:25:11 INFO NettyBlockTransferService: Server created on 10.138.10.11:41411
17/05/11 23:25:11 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
17/05/11 23:25:11 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(0, 10.138.10.11, 41411, None)
17/05/11 23:25:11 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(0, 10.138.10.11, 41411, None)
17/05/11 23:25:11 INFO BlockManager: Initialized BlockManager: BlockManagerId(0, 10.138.10.11, 41411, None)
17/05/11 23:25:11 INFO CoarseGrainedExecutorBackend: Got assigned task 0
17/05/11 23:25:11 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
17/05/11 23:25:12 INFO Executor: Fetching spark://10.138.10.6:36674/files/es_scatter.py with timestamp 1494563105768
17/05/11 23:25:12 INFO TransportClientFactory: Successfully created connection to /10.138.10.6:36674 after 3 ms (0 ms spent in bootstraps)
17/05/11 23:25:12 INFO Utils: Fetching spark://10.138.10.6:36674/files/es_scatter.py to /lustre/work/swanson/jdixon/tmp/spark-4186fe0a-9cd5-4dbb-9b2c-44e7ae932b75/executor-eef2a49b-f0df-4f89-8a9b-3079f70613da/spark-6e896058-5f2f-45fc-81ef-e613a4068230/fetchFileTemp6347575134266846672.tmp
17/05/11 23:25:12 INFO Utils: Copying /lustre/work/swanson/jdixon/tmp/spark-4186fe0a-9cd5-4dbb-9b2c-44e7ae932b75/executor-eef2a49b-f0df-4f89-8a9b-3079f70613da/spark-6e896058-5f2f-45fc-81ef-e613a4068230/-10034116381494563105768_cache to /lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/work/app-20170511232506-0000/0/./es_scatter.py
17/05/11 23:25:12 INFO Executor: Fetching spark://10.138.10.6:36674/jars/elasticsearch-hadoop-6.0.0.BUILD.SNAPSHOT.jar with timestamp 1494563105498
17/05/11 23:25:12 INFO Utils: Fetching spark://10.138.10.6:36674/jars/elasticsearch-hadoop-6.0.0.BUILD.SNAPSHOT.jar to /lustre/work/swanson/jdixon/tmp/spark-4186fe0a-9cd5-4dbb-9b2c-44e7ae932b75/executor-eef2a49b-f0df-4f89-8a9b-3079f70613da/spark-6e896058-5f2f-45fc-81ef-e613a4068230/fetchFileTemp6638251788404001766.tmp
17/05/11 23:25:12 INFO Utils: Copying /lustre/work/swanson/jdixon/tmp/spark-4186fe0a-9cd5-4dbb-9b2c-44e7ae932b75/executor-eef2a49b-f0df-4f89-8a9b-3079f70613da/spark-6e896058-5f2f-45fc-81ef-e613a4068230/-13275464181494563105498_cache to /lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/work/app-20170511232506-0000/0/./elasticsearch-hadoop-6.0.0.BUILD.SNAPSHOT.jar
17/05/11 23:25:12 INFO Executor: Adding file:/lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/work/app-20170511232506-0000/0/./elasticsearch-hadoop-6.0.0.BUILD.SNAPSHOT.jar to class loader
17/05/11 23:25:12 INFO TorrentBroadcast: Started reading broadcast variable 2
17/05/11 23:25:12 INFO TransportClientFactory: Successfully created connection to /10.138.10.6:38632 after 2 ms (0 ms spent in bootstraps)
17/05/11 23:25:12 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 1790.0 B, free 912.3 MB)
17/05/11 23:25:12 INFO TorrentBroadcast: Reading broadcast variable 2 took 210 ms
17/05/11 23:25:12 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 2.9 KB, free 912.3 MB)
17/05/11 23:25:12 INFO NewHadoopRDD: Input split: org.elasticsearch.hadoop.mr.EsInputFormat$EsInputSplit@346f4190
17/05/11 23:25:12 INFO TorrentBroadcast: Started reading broadcast variable 0
17/05/11 23:25:12 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.2 KB, free 912.3 MB)
17/05/11 23:25:12 INFO TorrentBroadcast: Reading broadcast variable 0 took 21 ms
17/05/11 23:25:13 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 294.9 KB, free 912.0 MB)
17/05/11 23:25:13 INFO deprecation: mapred.mapoutput.value.class is deprecated. Instead, use mapreduce.map.output.value.class
17/05/11 23:25:14 INFO deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
17/05/11 23:25:14 INFO deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id
17/05/11 23:25:14 WARN EsInputFormat: Cannot determine task id...
17/05/11 23:25:17 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 4589 bytes result sent to driver
17/05/11 23:25:17 INFO CoarseGrainedExecutorBackend: Got assigned task 1
17/05/11 23:25:17 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
17/05/11 23:25:17 INFO CoarseGrainedExecutorBackend: Got assigned task 2
17/05/11 23:25:17 INFO Executor: Running task 1.0 in stage 1.0 (TID 2)
17/05/11 23:25:17 INFO CoarseGrainedExecutorBackend: Got assigned task 3
17/05/11 23:25:17 INFO Executor: Running task 2.0 in stage 1.0 (TID 3)
17/05/11 23:25:17 INFO CoarseGrainedExecutorBackend: Got assigned task 4
17/05/11 23:25:17 INFO CoarseGrainedExecutorBackend: Got assigned task 5
17/05/11 23:25:17 INFO Executor: Running task 3.0 in stage 1.0 (TID 4)
17/05/11 23:25:17 INFO TorrentBroadcast: Started reading broadcast variable 3
17/05/11 23:25:17 INFO Executor: Running task 4.0 in stage 1.0 (TID 5)
17/05/11 23:25:17 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 6.5 KB, free 912.0 MB)
17/05/11 23:25:17 INFO TorrentBroadcast: Reading broadcast variable 3 took 25 ms
17/05/11 23:25:17 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 10.5 KB, free 912.0 MB)
17/05/11 23:25:18 INFO NewHadoopRDD: Input split: org.elasticsearch.hadoop.mr.EsInputFormat$EsInputSplit@1def1f1e
17/05/11 23:25:18 INFO NewHadoopRDD: Input split: org.elasticsearch.hadoop.mr.EsInputFormat$EsInputSplit@78a133ff
17/05/11 23:25:18 INFO NewHadoopRDD: Input split: org.elasticsearch.hadoop.mr.EsInputFormat$EsInputSplit@1f5ce838
17/05/11 23:25:18 INFO NewHadoopRDD: Input split: org.elasticsearch.hadoop.mr.EsInputFormat$EsInputSplit@3de3f9ec
17/05/11 23:25:18 INFO NewHadoopRDD: Input split: org.elasticsearch.hadoop.mr.EsInputFormat$EsInputSplit@1da9d40f
17/05/11 23:25:18 WARN EsInputFormat: Cannot determine task id...
17/05/11 23:25:18 WARN EsInputFormat: Cannot determine task id...
17/05/11 23:25:18 WARN EsInputFormat: Cannot determine task id...
17/05/11 23:25:18 WARN EsInputFormat: Cannot determine task id...
17/05/11 23:25:18 WARN EsInputFormat: Cannot determine task id...
17/05/11 23:25:28 INFO PythonRunner: Times: total = 9915, boot = 1784, init = 2846, finish = 5285
17/05/11 23:25:28 INFO MemoryStore: Block rdd_3_0 stored as bytes in memory (estimated size 6.5 MB, free 905.5 MB)
17/05/11 23:25:28 INFO PythonRunner: Times: total = 9967, boot = 1776, init = 2802, finish = 5389
17/05/11 23:25:28 INFO MemoryStore: Block rdd_3_2 stored as bytes in memory (estimated size 6.3 MB, free 899.2 MB)
17/05/11 23:25:28 INFO PythonRunner: Times: total = 9984, boot = 1769, init = 3016, finish = 5199
17/05/11 23:25:28 INFO MemoryStore: Block rdd_3_4 stored as bytes in memory (estimated size 6.4 MB, free 892.8 MB)
17/05/11 23:25:28 INFO PythonRunner: Times: total = 10225, boot = 1764, init = 3022, finish = 5439
17/05/11 23:25:28 INFO MemoryStore: Block rdd_3_3 stored as bytes in memory (estimated size 6.4 MB, free 886.4 MB)
17/05/11 23:25:28 INFO PythonRunner: Times: total = 10328, boot = 1785, init = 2917, finish = 5626
17/05/11 23:25:28 INFO MemoryStore: Block rdd_3_1 stored as bytes in memory (estimated size 6.5 MB, free 879.9 MB)
17/05/11 23:25:28 INFO PythonRunner: Times: total = 374, boot = -38, init = 48, finish = 364
17/05/11 23:25:28 INFO PythonRunner: Times: total = 458, boot = -35, init = 56, finish = 437
17/05/11 23:25:28 INFO PythonRunner: Times: total = 521, boot = -36, init = 53, finish = 504
17/05/11 23:25:28 INFO Executor: Finished task 2.0 in stage 1.0 (TID 3). 2560 bytes result sent to driver
17/05/11 23:25:28 INFO Executor: Finished task 4.0 in stage 1.0 (TID 5). 2473 bytes result sent to driver
17/05/11 23:25:28 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 2680 bytes result sent to driver
17/05/11 23:25:28 INFO PythonRunner: Times: total = 366, boot = -8, init = 24, finish = 350
17/05/11 23:25:28 INFO Executor: Finished task 3.0 in stage 1.0 (TID 4). 2473 bytes result sent to driver
17/05/11 23:25:28 INFO PythonRunner: Times: total = 366, boot = 30, init = 18, finish = 318
17/05/11 23:25:28 INFO Executor: Finished task 1.0 in stage 1.0 (TID 2). 2473 bytes result sent to driver
17/05/11 23:25:28 INFO CoarseGrainedExecutorBackend: Got assigned task 6
17/05/11 23:25:28 INFO Executor: Running task 0.0 in stage 2.0 (TID 6)
17/05/11 23:25:28 INFO CoarseGrainedExecutorBackend: Got assigned task 7
17/05/11 23:25:28 INFO Executor: Running task 1.0 in stage 2.0 (TID 7)
17/05/11 23:25:28 INFO CoarseGrainedExecutorBackend: Got assigned task 8
17/05/11 23:25:28 INFO Executor: Running task 2.0 in stage 2.0 (TID 8)
17/05/11 23:25:28 INFO MapOutputTrackerWorker: Updating epoch to 1 and clearing cache
17/05/11 23:25:28 INFO TorrentBroadcast: Started reading broadcast variable 4
17/05/11 23:25:28 INFO CoarseGrainedExecutorBackend: Got assigned task 9
17/05/11 23:25:28 INFO Executor: Running task 4.0 in stage 2.0 (TID 9)
17/05/11 23:25:28 INFO CoarseGrainedExecutorBackend: Got assigned task 10
17/05/11 23:25:28 INFO Executor: Running task 3.0 in stage 2.0 (TID 10)
17/05/11 23:25:28 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 4.5 KB, free 879.9 MB)
17/05/11 23:25:29 INFO TorrentBroadcast: Reading broadcast variable 4 took 23 ms
17/05/11 23:25:29 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 7.1 KB, free 879.9 MB)
17/05/11 23:25:29 INFO MapOutputTrackerWorker: Don't have map outputs for shuffle 0, fetching them
17/05/11 23:25:29 INFO MapOutputTrackerWorker: Don't have map outputs for shuffle 0, fetching them
17/05/11 23:25:29 INFO MapOutputTrackerWorker: Don't have map outputs for shuffle 0, fetching them
17/05/11 23:25:29 INFO MapOutputTrackerWorker: Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@10.138.10.6:36674)
17/05/11 23:25:29 INFO MapOutputTrackerWorker: Don't have map outputs for shuffle 0, fetching them
17/05/11 23:25:29 INFO MapOutputTrackerWorker: Don't have map outputs for shuffle 0, fetching them
17/05/11 23:25:29 INFO MapOutputTrackerWorker: Got the output locations
17/05/11 23:25:29 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/05/11 23:25:29 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/05/11 23:25:29 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/05/11 23:25:29 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 5 blocks
17/05/11 23:25:29 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/05/11 23:25:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 10 ms
17/05/11 23:25:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 10 ms
17/05/11 23:25:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 10 ms
17/05/11 23:25:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 10 ms
17/05/11 23:25:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 11 ms
17/05/11 23:25:29 INFO PythonRunner: Times: total = 28, boot = -412, init = 439, finish = 1
17/05/11 23:25:29 INFO Executor: Finished task 1.0 in stage 2.0 (TID 7). 2258 bytes result sent to driver
17/05/11 23:25:29 INFO PythonRunner: Times: total = 42, boot = -506, init = 547, finish = 1
17/05/11 23:25:29 INFO Executor: Finished task 3.0 in stage 2.0 (TID 10). 2091 bytes result sent to driver
17/05/11 23:25:29 INFO PythonRunner: Times: total = 42, boot = -434, init = 475, finish = 1
17/05/11 23:25:29 INFO Executor: Finished task 4.0 in stage 2.0 (TID 9). 2140 bytes result sent to driver
17/05/11 23:25:29 INFO PythonRunner: Times: total = 52, boot = -292, init = 341, finish = 3
17/05/11 23:25:29 INFO Executor: Finished task 2.0 in stage 2.0 (TID 8). 2192 bytes result sent to driver
17/05/11 23:25:29 INFO PythonRunner: Times: total = 45, boot = -258, init = 301, finish = 2
17/05/11 23:25:29 INFO Executor: Finished task 0.0 in stage 2.0 (TID 6). 2729 bytes result sent to driver
17/05/11 23:25:29 INFO CoarseGrainedExecutorBackend: Got assigned task 11
17/05/11 23:25:29 INFO Executor: Running task 0.0 in stage 3.0 (TID 11)
17/05/11 23:25:29 INFO CoarseGrainedExecutorBackend: Got assigned task 12
17/05/11 23:25:29 INFO Executor: Running task 1.0 in stage 3.0 (TID 12)
17/05/11 23:25:29 INFO CoarseGrainedExecutorBackend: Got assigned task 13
17/05/11 23:25:29 INFO Executor: Running task 2.0 in stage 3.0 (TID 13)
17/05/11 23:25:29 INFO TorrentBroadcast: Started reading broadcast variable 5
17/05/11 23:25:29 INFO CoarseGrainedExecutorBackend: Got assigned task 14
17/05/11 23:25:29 INFO Executor: Running task 3.0 in stage 3.0 (TID 14)
17/05/11 23:25:29 INFO CoarseGrainedExecutorBackend: Got assigned task 15
17/05/11 23:25:29 INFO Executor: Running task 4.0 in stage 3.0 (TID 15)
17/05/11 23:25:29 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 6.5 KB, free 879.9 MB)
17/05/11 23:25:29 INFO TorrentBroadcast: Reading broadcast variable 5 took 18 ms
17/05/11 23:25:29 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 10.5 KB, free 879.9 MB)
17/05/11 23:25:29 INFO BlockManager: Found block rdd_3_2 locally
17/05/11 23:25:29 INFO BlockManager: Found block rdd_3_1 locally
17/05/11 23:25:29 INFO BlockManager: Found block rdd_3_3 locally
17/05/11 23:25:29 INFO BlockManager: Found block rdd_3_4 locally
17/05/11 23:25:29 INFO BlockManager: Found block rdd_3_0 locally
17/05/11 23:25:29 INFO PythonRunner: Times: total = 306, boot = -194, init = 272, finish = 228
17/05/11 23:25:29 INFO Executor: Finished task 3.0 in stage 3.0 (TID 14). 2041 bytes result sent to driver
17/05/11 23:25:29 INFO PythonRunner: Times: total = 460, boot = -206, init = 210, finish = 456
17/05/11 23:25:29 INFO PythonRunner: Times: total = 464, boot = -177, init = 304, finish = 337
17/05/11 23:25:29 INFO PythonRunner: Times: total = 493, boot = -174, init = 210, finish = 457
17/05/11 23:25:29 INFO Executor: Finished task 2.0 in stage 3.0 (TID 13). 2041 bytes result sent to driver
17/05/11 23:25:29 INFO PythonRunner: Times: total = 515, boot = -196, init = 271, finish = 440
17/05/11 23:25:29 INFO Executor: Finished task 0.0 in stage 3.0 (TID 11). 2572 bytes result sent to driver
17/05/11 23:25:29 INFO Executor: Finished task 4.0 in stage 3.0 (TID 15). 2041 bytes result sent to driver
17/05/11 23:25:29 INFO Executor: Finished task 1.0 in stage 3.0 (TID 12). 2041 bytes result sent to driver
17/05/11 23:25:29 INFO CoarseGrainedExecutorBackend: Got assigned task 16
17/05/11 23:25:29 INFO Executor: Running task 0.0 in stage 4.0 (TID 16)
17/05/11 23:25:29 INFO CoarseGrainedExecutorBackend: Got assigned task 17
17/05/11 23:25:29 INFO CoarseGrainedExecutorBackend: Got assigned task 18
17/05/11 23:25:29 INFO Executor: Running task 1.0 in stage 4.0 (TID 18)
17/05/11 23:25:29 INFO CoarseGrainedExecutorBackend: Got assigned task 19
17/05/11 23:25:29 INFO Executor: Running task 3.0 in stage 4.0 (TID 19)
17/05/11 23:25:29 INFO Executor: Running task 2.0 in stage 4.0 (TID 17)
17/05/11 23:25:29 INFO MapOutputTrackerWorker: Updating epoch to 2 and clearing cache
17/05/11 23:25:29 INFO TorrentBroadcast: Started reading broadcast variable 6
17/05/11 23:25:29 INFO CoarseGrainedExecutorBackend: Got assigned task 20
17/05/11 23:25:29 INFO Executor: Running task 4.0 in stage 4.0 (TID 20)
17/05/11 23:25:29 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 4.5 KB, free 879.9 MB)
17/05/11 23:25:29 INFO TorrentBroadcast: Reading broadcast variable 6 took 22 ms
17/05/11 23:25:29 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 7.1 KB, free 879.9 MB)
17/05/11 23:25:29 INFO MapOutputTrackerWorker: Don't have map outputs for shuffle 1, fetching them
17/05/11 23:25:29 INFO MapOutputTrackerWorker: Don't have map outputs for shuffle 1, fetching them
17/05/11 23:25:29 INFO MapOutputTrackerWorker: Don't have map outputs for shuffle 1, fetching them
17/05/11 23:25:29 INFO MapOutputTrackerWorker: Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@10.138.10.6:36674)
17/05/11 23:25:29 INFO MapOutputTrackerWorker: Don't have map outputs for shuffle 1, fetching them
17/05/11 23:25:29 INFO MapOutputTrackerWorker: Don't have map outputs for shuffle 1, fetching them
17/05/11 23:25:29 INFO MapOutputTrackerWorker: Got the output locations
17/05/11 23:25:29 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 5 blocks
17/05/11 23:25:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/05/11 23:25:29 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 5 blocks
17/05/11 23:25:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/05/11 23:25:29 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/05/11 23:25:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/05/11 23:25:29 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 5 blocks
17/05/11 23:25:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/05/11 23:25:29 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/05/11 23:25:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms
17/05/11 23:25:30 INFO PythonRunner: Times: total = 4, boot = -319, init = 323, finish = 0
17/05/11 23:25:30 INFO Executor: Finished task 4.0 in stage 4.0 (TID 20). 2091 bytes result sent to driver
17/05/11 23:25:30 INFO PythonRunner: Times: total = 13, boot = -137, init = 149, finish = 1
17/05/11 23:25:30 INFO Executor: Finished task 1.0 in stage 4.0 (TID 18). 2622 bytes result sent to driver
17/05/11 23:25:30 INFO PythonRunner: Times: total = 44, boot = -170, init = 214, finish = 0
17/05/11 23:25:30 INFO Executor: Finished task 3.0 in stage 4.0 (TID 19). 2091 bytes result sent to driver
17/05/11 23:25:30 INFO PythonRunner: Times: total = 41, boot = -147, init = 188, finish = 0
17/05/11 23:25:30 INFO Executor: Finished task 2.0 in stage 4.0 (TID 17). 2175 bytes result sent to driver
17/05/11 23:25:30 INFO PythonRunner: Times: total = 50, boot = -134, init = 183, finish = 1
17/05/11 23:25:30 INFO Executor: Finished task 0.0 in stage 4.0 (TID 16). 2175 bytes result sent to driver
17/05/11 23:25:30 INFO CoarseGrainedExecutorBackend: Got assigned task 21
17/05/11 23:25:30 INFO Executor: Running task 0.0 in stage 5.0 (TID 21)
17/05/11 23:25:30 INFO CoarseGrainedExecutorBackend: Got assigned task 22
17/05/11 23:25:30 INFO Executor: Running task 1.0 in stage 5.0 (TID 22)
17/05/11 23:25:30 INFO CoarseGrainedExecutorBackend: Got assigned task 23
17/05/11 23:25:30 INFO Executor: Running task 2.0 in stage 5.0 (TID 23)
17/05/11 23:25:30 INFO TorrentBroadcast: Started reading broadcast variable 7
17/05/11 23:25:30 INFO CoarseGrainedExecutorBackend: Got assigned task 24
17/05/11 23:25:30 INFO Executor: Running task 3.0 in stage 5.0 (TID 24)
17/05/11 23:25:30 INFO CoarseGrainedExecutorBackend: Got assigned task 25
17/05/11 23:25:30 INFO Executor: Running task 4.0 in stage 5.0 (TID 25)
17/05/11 23:25:30 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 6.5 KB, free 879.9 MB)
17/05/11 23:25:30 INFO TorrentBroadcast: Reading broadcast variable 7 took 16 ms
17/05/11 23:25:30 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 10.5 KB, free 879.8 MB)
17/05/11 23:25:30 INFO BlockManager: Found block rdd_3_1 locally
17/05/11 23:25:30 INFO BlockManager: Found block rdd_3_0 locally
17/05/11 23:25:30 INFO BlockManager: Found block rdd_3_2 locally
17/05/11 23:25:30 INFO BlockManager: Found block rdd_3_3 locally
17/05/11 23:25:30 INFO BlockManager: Found block rdd_3_4 locally
17/05/11 23:25:30 INFO PythonRunner: Times: total = 293, boot = -166, init = 192, finish = 267
17/05/11 23:25:30 INFO Executor: Finished task 4.0 in stage 5.0 (TID 25). 2041 bytes result sent to driver
17/05/11 23:25:30 INFO PythonRunner: Times: total = 359, boot = -231, init = 260, finish = 330
17/05/11 23:25:30 INFO Executor: Finished task 1.0 in stage 5.0 (TID 22). 2041 bytes result sent to driver
17/05/11 23:25:30 INFO PythonRunner: Times: total = 447, boot = -190, init = 235, finish = 402
17/05/11 23:25:30 INFO PythonRunner: Times: total = 499, boot = -164, init = 267, finish = 396
17/05/11 23:25:30 INFO PythonRunner: Times: total = 505, boot = -214, init = 280, finish = 439
17/05/11 23:25:30 INFO Executor: Finished task 2.0 in stage 5.0 (TID 23). 2114 bytes result sent to driver
17/05/11 23:25:30 INFO Executor: Finished task 3.0 in stage 5.0 (TID 24). 2114 bytes result sent to driver
17/05/11 23:25:30 INFO Executor: Finished task 0.0 in stage 5.0 (TID 21). 2645 bytes result sent to driver
17/05/11 23:25:30 INFO CoarseGrainedExecutorBackend: Got assigned task 26
17/05/11 23:25:30 INFO Executor: Running task 0.0 in stage 6.0 (TID 26)
17/05/11 23:25:30 INFO CoarseGrainedExecutorBackend: Got assigned task 27
17/05/11 23:25:30 INFO CoarseGrainedExecutorBackend: Got assigned task 28
17/05/11 23:25:30 INFO CoarseGrainedExecutorBackend: Got assigned task 29
17/05/11 23:25:30 INFO CoarseGrainedExecutorBackend: Got assigned task 30
17/05/11 23:25:30 INFO Executor: Running task 4.0 in stage 6.0 (TID 30)
17/05/11 23:25:30 INFO Executor: Running task 1.0 in stage 6.0 (TID 27)
17/05/11 23:25:30 INFO MapOutputTrackerWorker: Updating epoch to 3 and clearing cache
17/05/11 23:25:30 INFO TorrentBroadcast: Started reading broadcast variable 8
17/05/11 23:25:30 INFO Executor: Running task 3.0 in stage 6.0 (TID 29)
17/05/11 23:25:30 INFO Executor: Running task 2.0 in stage 6.0 (TID 28)
17/05/11 23:25:30 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 4.5 KB, free 879.8 MB)
17/05/11 23:25:30 INFO TorrentBroadcast: Reading broadcast variable 8 took 17 ms
17/05/11 23:25:30 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 7.1 KB, free 879.8 MB)
17/05/11 23:25:30 INFO MapOutputTrackerWorker: Don't have map outputs for shuffle 2, fetching them
17/05/11 23:25:30 INFO MapOutputTrackerWorker: Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@10.138.10.6:36674)
17/05/11 23:25:30 INFO MapOutputTrackerWorker: Don't have map outputs for shuffle 2, fetching them
17/05/11 23:25:30 INFO MapOutputTrackerWorker: Got the output locations
17/05/11 23:25:30 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/05/11 23:25:30 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/05/11 23:25:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/05/11 23:25:30 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/05/11 23:25:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/05/11 23:25:30 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/05/11 23:25:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/05/11 23:25:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/05/11 23:25:30 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/05/11 23:25:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/05/11 23:25:30 INFO PythonRunner: Times: total = 50, boot = -337, init = 385, finish = 2
17/05/11 23:25:30 INFO PythonRunner: Times: total = 47, boot = -198, init = 244, finish = 1
17/05/11 23:25:30 INFO Executor: Finished task 3.0 in stage 6.0 (TID 29). 5709 bytes result sent to driver
17/05/11 23:25:30 INFO Executor: Finished task 2.0 in stage 6.0 (TID 28). 6308 bytes result sent to driver
17/05/11 23:25:30 INFO PythonRunner: Times: total = 46, boot = -146, init = 191, finish = 1
17/05/11 23:25:30 INFO Executor: Finished task 1.0 in stage 6.0 (TID 27). 5763 bytes result sent to driver
17/05/11 23:25:30 INFO PythonRunner: Times: total = 51, boot = -168, init = 218, finish = 1
17/05/11 23:25:30 INFO PythonRunner: Times: total = 55, boot = -295, init = 349, finish = 1
17/05/11 23:25:30 INFO Executor: Finished task 0.0 in stage 6.0 (TID 26). 6329 bytes result sent to driver
17/05/11 23:25:30 INFO Executor: Finished task 4.0 in stage 6.0 (TID 30). 5611 bytes result sent to driver
17/05/11 23:25:31 INFO CoarseGrainedExecutorBackend: Got assigned task 31
17/05/11 23:25:31 INFO Executor: Running task 0.0 in stage 7.0 (TID 31)
17/05/11 23:25:31 INFO TorrentBroadcast: Started reading broadcast variable 9
17/05/11 23:25:31 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 4.8 KB, free 879.8 MB)
17/05/11 23:25:31 INFO TorrentBroadcast: Reading broadcast variable 9 took 10 ms
17/05/11 23:25:31 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 8.9 KB, free 879.8 MB)
17/05/11 23:25:31 INFO BlockManager: Found block rdd_3_0 locally
17/05/11 23:25:31 INFO PythonRunner: Times: total = 428, boot = -150, init = 152, finish = 426
17/05/11 23:25:31 INFO MemoryStore: Block rdd_19_0 stored as bytes in memory (estimated size 808.2 KB, free 879.0 MB)
17/05/11 23:25:31 INFO PythonRunner: Times: total = 25, boot = -584, init = 587, finish = 22
17/05/11 23:25:31 INFO Executor: Finished task 0.0 in stage 7.0 (TID 31). 2344 bytes result sent to driver
17/05/11 23:25:31 INFO CoarseGrainedExecutorBackend: Got assigned task 32
17/05/11 23:25:31 INFO Executor: Running task 0.0 in stage 8.0 (TID 32)
17/05/11 23:25:31 INFO TorrentBroadcast: Started reading broadcast variable 10
17/05/11 23:25:31 INFO CoarseGrainedExecutorBackend: Got assigned task 33
17/05/11 23:25:31 INFO Executor: Running task 1.0 in stage 8.0 (TID 33)
17/05/11 23:25:31 INFO CoarseGrainedExecutorBackend: Got assigned task 34
17/05/11 23:25:31 INFO Executor: Running task 2.0 in stage 8.0 (TID 34)
17/05/11 23:25:31 INFO CoarseGrainedExecutorBackend: Got assigned task 35
17/05/11 23:25:31 INFO Executor: Running task 3.0 in stage 8.0 (TID 35)
17/05/11 23:25:31 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 4.8 KB, free 879.0 MB)
17/05/11 23:25:31 INFO TorrentBroadcast: Reading broadcast variable 10 took 22 ms
17/05/11 23:25:31 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 8.9 KB, free 879.0 MB)
17/05/11 23:25:31 INFO BlockManager: Found block rdd_3_2 locally
17/05/11 23:25:31 INFO BlockManager: Found block rdd_3_3 locally
17/05/11 23:25:31 INFO BlockManager: Found block rdd_3_4 locally
17/05/11 23:25:31 INFO BlockManager: Found block rdd_3_1 locally
17/05/11 23:25:32 INFO PythonRunner: Times: total = 312, boot = -705, init = 741, finish = 276
17/05/11 23:25:32 INFO MemoryStore: Block rdd_19_4 stored as bytes in memory (estimated size 770.2 KB, free 878.3 MB)
17/05/11 23:25:32 INFO PythonRunner: Times: total = 298, boot = -125, init = 131, finish = 292
17/05/11 23:25:32 INFO MemoryStore: Block rdd_19_1 stored as bytes in memory (estimated size 849.4 KB, free 877.4 MB)
17/05/11 23:25:32 INFO PythonRunner: Times: total = 29, boot = -435, init = 436, finish = 28
17/05/11 23:25:32 INFO Executor: Finished task 3.0 in stage 8.0 (TID 35). 2137 bytes result sent to driver
17/05/11 23:25:32 INFO PythonRunner: Times: total = 45, boot = -35, init = 52, finish = 28
17/05/11 23:25:32 INFO Executor: Finished task 0.0 in stage 8.0 (TID 32). 2344 bytes result sent to driver
17/05/11 23:25:32 INFO PythonRunner: Times: total = 426, boot = -707, init = 711, finish = 422
17/05/11 23:25:32 INFO MemoryStore: Block rdd_19_2 stored as bytes in memory (estimated size 788.1 KB, free 876.7 MB)
17/05/11 23:25:32 INFO PythonRunner: Times: total = 23, boot = -128, init = 130, finish = 21
17/05/11 23:25:32 INFO Executor: Finished task 1.0 in stage 8.0 (TID 33). 2137 bytes result sent to driver
17/05/11 23:25:32 INFO PythonRunner: Times: total = 441, boot = -699, init = 714, finish = 426
17/05/11 23:25:32 INFO MemoryStore: Block rdd_19_3 stored as bytes in memory (estimated size 758.8 KB, free 875.9 MB)
17/05/11 23:25:32 INFO PythonRunner: Times: total = 22, boot = -103, init = 104, finish = 21
17/05/11 23:25:32 INFO Executor: Finished task 2.0 in stage 8.0 (TID 34). 2137 bytes result sent to driver
17/05/11 23:25:32 INFO CoarseGrainedExecutorBackend: Got assigned task 36
17/05/11 23:25:32 INFO Executor: Running task 0.0 in stage 9.0 (TID 36)
17/05/11 23:25:32 INFO TorrentBroadcast: Started reading broadcast variable 11
17/05/11 23:25:32 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 4.8 KB, free 875.9 MB)
17/05/11 23:25:32 INFO TorrentBroadcast: Reading broadcast variable 11 took 10 ms
17/05/11 23:25:32 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 8.9 KB, free 875.9 MB)
17/05/11 23:25:32 INFO BlockManager: Found block rdd_19_0 locally
17/05/11 23:25:32 INFO PythonRunner: Times: total = 4, boot = -170, init = 171, finish = 3
17/05/11 23:25:32 INFO Executor: Finished task 0.0 in stage 9.0 (TID 36). 4463 bytes result sent to driver
17/05/11 23:25:32 INFO CoarseGrainedExecutorBackend: Got assigned task 37
17/05/11 23:25:32 INFO Executor: Running task 0.0 in stage 10.0 (TID 37)
17/05/11 23:25:32 INFO TorrentBroadcast: Started reading broadcast variable 12
17/05/11 23:25:32 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 5.0 KB, free 875.9 MB)
17/05/11 23:25:32 INFO TorrentBroadcast: Reading broadcast variable 12 took 9 ms
17/05/11 23:25:32 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 9.1 KB, free 875.9 MB)
17/05/11 23:25:32 INFO BlockManager: Found block rdd_19_0 locally
17/05/11 23:25:32 INFO PythonRunner: Times: total = 23, boot = -227, init = 229, finish = 21
17/05/11 23:25:32 INFO Executor: Finished task 0.0 in stage 10.0 (TID 37). 2317 bytes result sent to driver
17/05/11 23:25:32 INFO CoarseGrainedExecutorBackend: Got assigned task 38
17/05/11 23:25:32 INFO Executor: Running task 0.0 in stage 11.0 (TID 38)
17/05/11 23:25:32 INFO TorrentBroadcast: Started reading broadcast variable 13
17/05/11 23:25:32 INFO CoarseGrainedExecutorBackend: Got assigned task 39
17/05/11 23:25:32 INFO CoarseGrainedExecutorBackend: Got assigned task 40
17/05/11 23:25:32 INFO CoarseGrainedExecutorBackend: Got assigned task 41
17/05/11 23:25:32 INFO Executor: Running task 1.0 in stage 11.0 (TID 39)
17/05/11 23:25:32 INFO Executor: Running task 2.0 in stage 11.0 (TID 40)
17/05/11 23:25:32 INFO Executor: Running task 3.0 in stage 11.0 (TID 41)
17/05/11 23:25:32 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 5.0 KB, free 875.9 MB)
17/05/11 23:25:32 INFO TorrentBroadcast: Reading broadcast variable 13 took 22 ms
17/05/11 23:25:32 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 9.1 KB, free 875.9 MB)
17/05/11 23:25:32 INFO BlockManager: Found block rdd_19_3 locally
17/05/11 23:25:32 INFO BlockManager: Found block rdd_19_2 locally
17/05/11 23:25:32 INFO BlockManager: Found block rdd_19_4 locally
17/05/11 23:25:32 INFO BlockManager: Found block rdd_19_1 locally
17/05/11 23:25:32 INFO PythonRunner: Times: total = 47, boot = -240, init = 263, finish = 24
17/05/11 23:25:32 INFO PythonRunner: Times: total = 54, boot = -295, init = 308, finish = 41
17/05/11 23:25:32 INFO PythonRunner: Times: total = 34, boot = -78, init = 86, finish = 26
17/05/11 23:25:32 INFO Executor: Finished task 3.0 in stage 11.0 (TID 41). 1699 bytes result sent to driver
17/05/11 23:25:32 INFO Executor: Finished task 0.0 in stage 11.0 (TID 38). 2230 bytes result sent to driver
17/05/11 23:25:32 INFO Executor: Finished task 2.0 in stage 11.0 (TID 40). 1699 bytes result sent to driver
17/05/11 23:25:32 INFO PythonRunner: Times: total = 70, boot = -316, init = 357, finish = 29
17/05/11 23:25:32 INFO Executor: Finished task 1.0 in stage 11.0 (TID 39). 1699 bytes result sent to driver
17/05/11 23:25:32 INFO CoarseGrainedExecutorBackend: Got assigned task 42
17/05/11 23:25:32 INFO Executor: Running task 0.0 in stage 12.0 (TID 42)
17/05/11 23:25:32 INFO TorrentBroadcast: Started reading broadcast variable 14
17/05/11 23:25:32 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 5.0 KB, free 875.9 MB)
17/05/11 23:25:32 INFO TorrentBroadcast: Reading broadcast variable 14 took 10 ms
17/05/11 23:25:32 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 9.1 KB, free 875.9 MB)
17/05/11 23:25:32 INFO BlockManager: Found block rdd_19_0 locally
17/05/11 23:25:32 INFO PythonRunner: Times: total = 56, boot = -73, init = 83, finish = 46
17/05/11 23:25:32 INFO Executor: Finished task 0.0 in stage 12.0 (TID 42). 2230 bytes result sent to driver
17/05/11 23:25:32 INFO CoarseGrainedExecutorBackend: Got assigned task 43
17/05/11 23:25:32 INFO Executor: Running task 0.0 in stage 13.0 (TID 43)
17/05/11 23:25:32 INFO CoarseGrainedExecutorBackend: Got assigned task 44
17/05/11 23:25:32 INFO Executor: Running task 1.0 in stage 13.0 (TID 44)
17/05/11 23:25:32 INFO TorrentBroadcast: Started reading broadcast variable 15
17/05/11 23:25:32 INFO CoarseGrainedExecutorBackend: Got assigned task 45
17/05/11 23:25:32 INFO Executor: Running task 2.0 in stage 13.0 (TID 45)
17/05/11 23:25:32 INFO CoarseGrainedExecutorBackend: Got assigned task 46
17/05/11 23:25:32 INFO Executor: Running task 3.0 in stage 13.0 (TID 46)
17/05/11 23:25:32 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 5.0 KB, free 875.9 MB)
17/05/11 23:25:32 INFO TorrentBroadcast: Reading broadcast variable 15 took 15 ms
17/05/11 23:25:32 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 9.1 KB, free 875.9 MB)
17/05/11 23:25:32 INFO BlockManager: Found block rdd_19_3 locally
17/05/11 23:25:32 INFO BlockManager: Found block rdd_19_2 locally
17/05/11 23:25:32 INFO BlockManager: Found block rdd_19_1 locally
17/05/11 23:25:32 INFO BlockManager: Found block rdd_19_4 locally
17/05/11 23:25:32 INFO PythonRunner: Times: total = 32, boot = -179, init = 187, finish = 24
17/05/11 23:25:32 INFO Executor: Finished task 2.0 in stage 13.0 (TID 45). 1699 bytes result sent to driver
17/05/11 23:25:32 INFO PythonRunner: Times: total = 35, boot = -202, init = 210, finish = 27
17/05/11 23:25:32 INFO Executor: Finished task 1.0 in stage 13.0 (TID 44). 1699 bytes result sent to driver
17/05/11 23:25:32 INFO PythonRunner: Times: total = 48, boot = -172, init = 175, finish = 45
17/05/11 23:25:32 INFO Executor: Finished task 0.0 in stage 13.0 (TID 43). 2230 bytes result sent to driver
17/05/11 23:25:32 INFO PythonRunner: Times: total = 53, boot = -52, init = 64, finish = 41
17/05/11 23:25:32 INFO Executor: Finished task 3.0 in stage 13.0 (TID 46). 1699 bytes result sent to driver
17/05/11 23:25:32 INFO CoarseGrainedExecutorBackend: Got assigned task 47
17/05/11 23:25:32 INFO Executor: Running task 0.0 in stage 14.0 (TID 47)
17/05/11 23:25:32 INFO TorrentBroadcast: Started reading broadcast variable 16
17/05/11 23:25:32 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 5.0 KB, free 875.9 MB)
17/05/11 23:25:32 INFO TorrentBroadcast: Reading broadcast variable 16 took 11 ms
17/05/11 23:25:32 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 9.1 KB, free 875.8 MB)
17/05/11 23:25:32 INFO BlockManager: Found block rdd_19_0 locally
17/05/11 23:25:32 INFO PythonRunner: Times: total = 42, boot = -83, init = 84, finish = 41
17/05/11 23:25:32 INFO Executor: Finished task 0.0 in stage 14.0 (TID 47). 2230 bytes result sent to driver
17/05/11 23:25:32 INFO CoarseGrainedExecutorBackend: Got assigned task 48
17/05/11 23:25:32 INFO Executor: Running task 0.0 in stage 15.0 (TID 48)
17/05/11 23:25:32 INFO CoarseGrainedExecutorBackend: Got assigned task 49
17/05/11 23:25:32 INFO Executor: Running task 1.0 in stage 15.0 (TID 49)
17/05/11 23:25:32 INFO TorrentBroadcast: Started reading broadcast variable 17
17/05/11 23:25:32 INFO CoarseGrainedExecutorBackend: Got assigned task 50
17/05/11 23:25:32 INFO Executor: Running task 2.0 in stage 15.0 (TID 50)
17/05/11 23:25:32 INFO CoarseGrainedExecutorBackend: Got assigned task 51
17/05/11 23:25:32 INFO Executor: Running task 3.0 in stage 15.0 (TID 51)
17/05/11 23:25:32 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 5.0 KB, free 875.8 MB)
17/05/11 23:25:32 INFO TorrentBroadcast: Reading broadcast variable 17 took 13 ms
17/05/11 23:25:32 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 9.1 KB, free 875.8 MB)
17/05/11 23:25:32 INFO BlockManager: Found block rdd_19_4 locally
17/05/11 23:25:32 INFO BlockManager: Found block rdd_19_3 locally
17/05/11 23:25:32 INFO BlockManager: Found block rdd_19_2 locally
17/05/11 23:25:32 INFO BlockManager: Found block rdd_19_1 locally
17/05/11 23:25:32 INFO PythonRunner: Times: total = 24, boot = -192, init = 193, finish = 23
17/05/11 23:25:32 INFO PythonRunner: Times: total = 26, boot = -203, init = 204, finish = 25
17/05/11 23:25:32 INFO PythonRunner: Times: total = 30, boot = -188, init = 192, finish = 26
17/05/11 23:25:32 INFO Executor: Finished task 2.0 in stage 15.0 (TID 50). 1699 bytes result sent to driver
17/05/11 23:25:32 INFO Executor: Finished task 1.0 in stage 15.0 (TID 49). 1699 bytes result sent to driver
17/05/11 23:25:32 INFO Executor: Finished task 3.0 in stage 15.0 (TID 51). 1699 bytes result sent to driver
17/05/11 23:25:33 INFO PythonRunner: Times: total = 70, boot = -80, init = 110, finish = 40
17/05/11 23:25:33 INFO Executor: Finished task 0.0 in stage 15.0 (TID 48). 2230 bytes result sent to driver
17/05/11 23:25:33 INFO CoarseGrainedExecutorBackend: Got assigned task 52
17/05/11 23:25:33 INFO Executor: Running task 0.0 in stage 16.0 (TID 52)
17/05/11 23:25:33 INFO TorrentBroadcast: Started reading broadcast variable 18
17/05/11 23:25:33 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 5.0 KB, free 875.8 MB)
17/05/11 23:25:33 INFO TorrentBroadcast: Reading broadcast variable 18 took 14 ms
17/05/11 23:25:33 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 9.1 KB, free 875.8 MB)
17/05/11 23:25:33 INFO BlockManager: Found block rdd_19_0 locally
17/05/11 23:25:33 INFO PythonRunner: Times: total = 4, boot = -105, init = 106, finish = 3
17/05/11 23:25:33 INFO Executor: Finished task 0.0 in stage 16.0 (TID 52). 4463 bytes result sent to driver
17/05/11 23:25:33 INFO CoarseGrainedExecutorBackend: Got assigned task 53
17/05/11 23:25:33 INFO Executor: Running task 0.0 in stage 17.0 (TID 53)
17/05/11 23:25:33 INFO TorrentBroadcast: Started reading broadcast variable 19
17/05/11 23:25:33 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 5.0 KB, free 875.8 MB)
17/05/11 23:25:33 INFO TorrentBroadcast: Reading broadcast variable 19 took 11 ms
17/05/11 23:25:33 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 9.1 KB, free 875.8 MB)
17/05/11 23:25:33 INFO BlockManager: Found block rdd_19_0 locally
17/05/11 23:25:33 INFO PythonRunner: Times: total = 4, boot = -176, init = 177, finish = 3
17/05/11 23:25:33 INFO Executor: Finished task 0.0 in stage 17.0 (TID 53). 4463 bytes result sent to driver
17/05/11 23:25:33 INFO CoarseGrainedExecutorBackend: Got assigned task 54
17/05/11 23:25:33 INFO Executor: Running task 0.0 in stage 18.0 (TID 54)
17/05/11 23:25:33 INFO CoarseGrainedExecutorBackend: Got assigned task 55
17/05/11 23:25:33 INFO Executor: Running task 1.0 in stage 18.0 (TID 55)
17/05/11 23:25:33 INFO TorrentBroadcast: Started reading broadcast variable 20
17/05/11 23:25:33 INFO CoarseGrainedExecutorBackend: Got assigned task 56
17/05/11 23:25:33 INFO Executor: Running task 2.0 in stage 18.0 (TID 56)
17/05/11 23:25:33 INFO CoarseGrainedExecutorBackend: Got assigned task 57
17/05/11 23:25:33 INFO Executor: Running task 3.0 in stage 18.0 (TID 57)
17/05/11 23:25:33 INFO CoarseGrainedExecutorBackend: Got assigned task 58
17/05/11 23:25:33 INFO Executor: Running task 4.0 in stage 18.0 (TID 58)
17/05/11 23:25:33 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 5.5 KB, free 875.8 MB)
17/05/11 23:25:33 INFO TorrentBroadcast: Reading broadcast variable 20 took 16 ms
17/05/11 23:25:33 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 9.9 KB, free 875.8 MB)
17/05/11 23:25:33 INFO BlockManager: Found block rdd_19_3 locally
17/05/11 23:25:33 INFO BlockManager: Found block rdd_19_0 locally
17/05/11 23:25:33 INFO BlockManager: Found block rdd_19_1 locally
17/05/11 23:25:33 INFO BlockManager: Found block rdd_19_4 locally
17/05/11 23:25:33 INFO BlockManager: Found block rdd_19_2 locally
17/05/11 23:25:33 ERROR Executor: Exception in task 3.0 in stage 18.0 (TID 57)
org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/python/lib/pyspark.zip/pyspark/worker.py", line 174, in main
    process()
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/python/lib/pyspark.zip/pyspark/worker.py", line 169, in process
    serializer.dump_stream(func(split_index, iterator), outfile)
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/python/lib/pyspark.zip/pyspark/serializers.py", line 268, in dump_stream
    vs = list(itertools.islice(iterator, batch))
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/python/lib/pyspark.zip/pyspark/rdd.py", line 833, in func
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/SparkScripts/es_scatter.py", line 119, in snapPop
    counter = lastHost[lastHost[lastHost.rfind('.'):].rfind('.'):].rfind('.')
AttributeError: 'numpy.ndarray' object has no attribute 'rfind'

	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:193)
	at org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)
	at org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
17/05/11 23:25:33 ERROR Executor: Exception in task 0.0 in stage 18.0 (TID 54)
org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/python/lib/pyspark.zip/pyspark/worker.py", line 174, in main
    process()
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/python/lib/pyspark.zip/pyspark/worker.py", line 169, in process
    serializer.dump_stream(func(split_index, iterator), outfile)
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/python/lib/pyspark.zip/pyspark/serializers.py", line 268, in dump_stream
    vs = list(itertools.islice(iterator, batch))
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/python/lib/pyspark.zip/pyspark/rdd.py", line 833, in func
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/SparkScripts/es_scatter.py", line 119, in snapPop
    counter = lastHost[lastHost[lastHost.rfind('.'):].rfind('.'):].rfind('.')
AttributeError: 'numpy.ndarray' object has no attribute 'rfind'

	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:193)
	at org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)
	at org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
17/05/11 23:25:33 ERROR Executor: Exception in task 2.0 in stage 18.0 (TID 56)
org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/python/lib/pyspark.zip/pyspark/worker.py", line 174, in main
    process()
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/python/lib/pyspark.zip/pyspark/worker.py", line 169, in process
    serializer.dump_stream(func(split_index, iterator), outfile)
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/python/lib/pyspark.zip/pyspark/serializers.py", line 268, in dump_stream
    vs = list(itertools.islice(iterator, batch))
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/python/lib/pyspark.zip/pyspark/rdd.py", line 833, in func
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/SparkScripts/es_scatter.py", line 119, in snapPop
    counter = lastHost[lastHost[lastHost.rfind('.'):].rfind('.'):].rfind('.')
AttributeError: 'numpy.ndarray' object has no attribute 'rfind'

	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:193)
	at org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)
	at org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
17/05/11 23:25:33 ERROR Executor: Exception in task 1.0 in stage 18.0 (TID 55)
org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/python/lib/pyspark.zip/pyspark/worker.py", line 174, in main
    process()
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/python/lib/pyspark.zip/pyspark/worker.py", line 169, in process
    serializer.dump_stream(func(split_index, iterator), outfile)
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/python/lib/pyspark.zip/pyspark/serializers.py", line 268, in dump_stream
    vs = list(itertools.islice(iterator, batch))
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/python/lib/pyspark.zip/pyspark/rdd.py", line 833, in func
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/SparkScripts/es_scatter.py", line 119, in snapPop
    counter = lastHost[lastHost[lastHost.rfind('.'):].rfind('.'):].rfind('.')
AttributeError: 'numpy.ndarray' object has no attribute 'rfind'

	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:193)
	at org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)
	at org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
17/05/11 23:25:33 ERROR Executor: Exception in task 4.0 in stage 18.0 (TID 58)
org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/python/lib/pyspark.zip/pyspark/worker.py", line 174, in main
    process()
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/python/lib/pyspark.zip/pyspark/worker.py", line 169, in process
    serializer.dump_stream(func(split_index, iterator), outfile)
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/python/lib/pyspark.zip/pyspark/serializers.py", line 268, in dump_stream
    vs = list(itertools.islice(iterator, batch))
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/python/lib/pyspark.zip/pyspark/rdd.py", line 833, in func
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/SparkScripts/es_scatter.py", line 119, in snapPop
    counter = lastHost[lastHost[lastHost.rfind('.'):].rfind('.'):].rfind('.')
AttributeError: 'numpy.ndarray' object has no attribute 'rfind'

	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:193)
	at org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)
	at org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
17/05/11 23:25:33 INFO CoarseGrainedExecutorBackend: Got assigned task 59
17/05/11 23:25:33 INFO Executor: Running task 2.1 in stage 18.0 (TID 59)
17/05/11 23:25:33 INFO BlockManager: Found block rdd_19_2 locally
17/05/11 23:25:33 INFO CoarseGrainedExecutorBackend: Got assigned task 60
17/05/11 23:25:33 INFO CoarseGrainedExecutorBackend: Got assigned task 61
17/05/11 23:25:33 INFO Executor: Running task 3.1 in stage 18.0 (TID 61)
17/05/11 23:25:33 INFO CoarseGrainedExecutorBackend: Got assigned task 62
17/05/11 23:25:33 INFO Executor: Running task 4.1 in stage 18.0 (TID 62)
17/05/11 23:25:33 INFO CoarseGrainedExecutorBackend: Got assigned task 63
17/05/11 23:25:33 INFO Executor: Running task 1.1 in stage 18.0 (TID 63)
17/05/11 23:25:33 INFO BlockManager: Found block rdd_19_4 locally
17/05/11 23:25:33 INFO Executor: Running task 0.1 in stage 18.0 (TID 60)
17/05/11 23:25:33 INFO BlockManager: Found block rdd_19_3 locally
17/05/11 23:25:33 INFO BlockManager: Found block rdd_19_1 locally
17/05/11 23:25:33 INFO BlockManager: Found block rdd_19_0 locally
17/05/11 23:25:33 ERROR Executor: Exception in task 2.1 in stage 18.0 (TID 59)
org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/python/lib/pyspark.zip/pyspark/worker.py", line 174, in main
    process()
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/python/lib/pyspark.zip/pyspark/worker.py", line 169, in process
    serializer.dump_stream(func(split_index, iterator), outfile)
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/python/lib/pyspark.zip/pyspark/serializers.py", line 268, in dump_stream
    vs = list(itertools.islice(iterator, batch))
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/python/lib/pyspark.zip/pyspark/rdd.py", line 833, in func
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/SparkScripts/es_scatter.py", line 119, in snapPop
    counter = lastHost[lastHost[lastHost.rfind('.'):].rfind('.'):].rfind('.')
AttributeError: 'numpy.ndarray' object has no attribute 'rfind'

	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:193)
	at org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)
	at org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
17/05/11 23:25:33 INFO CoarseGrainedExecutorBackend: Got assigned task 64
17/05/11 23:25:33 INFO Executor: Running task 2.2 in stage 18.0 (TID 64)
17/05/11 23:25:33 INFO BlockManager: Found block rdd_19_2 locally
17/05/11 23:25:33 ERROR Executor: Exception in task 0.1 in stage 18.0 (TID 60)
org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/python/lib/pyspark.zip/pyspark/worker.py", line 174, in main
    process()
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/python/lib/pyspark.zip/pyspark/worker.py", line 169, in process
    serializer.dump_stream(func(split_index, iterator), outfile)
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/python/lib/pyspark.zip/pyspark/serializers.py", line 268, in dump_stream
    vs = list(itertools.islice(iterator, batch))
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/python/lib/pyspark.zip/pyspark/rdd.py", line 833, in func
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/SparkScripts/es_scatter.py", line 119, in snapPop
    counter = lastHost[lastHost[lastHost.rfind('.'):].rfind('.'):].rfind('.')
AttributeError: 'numpy.ndarray' object has no attribute 'rfind'

	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:193)
	at org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)
	at org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
17/05/11 23:25:33 INFO CoarseGrainedExecutorBackend: Got assigned task 65
17/05/11 23:25:33 ERROR Executor: Exception in task 1.1 in stage 18.0 (TID 63)
org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/python/lib/pyspark.zip/pyspark/worker.py", line 174, in main
    process()
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/python/lib/pyspark.zip/pyspark/worker.py", line 169, in process
    serializer.dump_stream(func(split_index, iterator), outfile)
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/python/lib/pyspark.zip/pyspark/serializers.py", line 268, in dump_stream
    vs = list(itertools.islice(iterator, batch))
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/python/lib/pyspark.zip/pyspark/rdd.py", line 833, in func
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/SparkScripts/es_scatter.py", line 119, in snapPop
    counter = lastHost[lastHost[lastHost.rfind('.'):].rfind('.'):].rfind('.')
AttributeError: 'numpy.ndarray' object has no attribute 'rfind'

	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:193)
	at org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)
	at org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
17/05/11 23:25:33 ERROR Executor: Exception in task 3.1 in stage 18.0 (TID 61)
org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/python/lib/pyspark.zip/pyspark/worker.py", line 174, in main
    process()
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/python/lib/pyspark.zip/pyspark/worker.py", line 169, in process
    serializer.dump_stream(func(split_index, iterator), outfile)
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/python/lib/pyspark.zip/pyspark/serializers.py", line 268, in dump_stream
    vs = list(itertools.islice(iterator, batch))
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/python/lib/pyspark.zip/pyspark/rdd.py", line 833, in func
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/SparkScripts/es_scatter.py", line 119, in snapPop
    counter = lastHost[lastHost[lastHost.rfind('.'):].rfind('.'):].rfind('.')
AttributeError: 'numpy.ndarray' object has no attribute 'rfind'

	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:193)
	at org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)
	at org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
17/05/11 23:25:33 INFO Executor: Running task 0.2 in stage 18.0 (TID 65)
17/05/11 23:25:33 INFO CoarseGrainedExecutorBackend: Got assigned task 66
17/05/11 23:25:33 INFO Executor: Running task 3.2 in stage 18.0 (TID 66)
17/05/11 23:25:33 INFO BlockManager: Found block rdd_19_3 locally
17/05/11 23:25:33 INFO CoarseGrainedExecutorBackend: Got assigned task 67
17/05/11 23:25:33 INFO Executor: Running task 1.2 in stage 18.0 (TID 67)
17/05/11 23:25:33 ERROR Executor: Exception in task 4.1 in stage 18.0 (TID 62)
org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/python/lib/pyspark.zip/pyspark/worker.py", line 174, in main
    process()
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/python/lib/pyspark.zip/pyspark/worker.py", line 169, in process
    serializer.dump_stream(func(split_index, iterator), outfile)
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/python/lib/pyspark.zip/pyspark/serializers.py", line 268, in dump_stream
    vs = list(itertools.islice(iterator, batch))
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/python/lib/pyspark.zip/pyspark/rdd.py", line 833, in func
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/SparkScripts/es_scatter.py", line 119, in snapPop
    counter = lastHost[lastHost[lastHost.rfind('.'):].rfind('.'):].rfind('.')
AttributeError: 'numpy.ndarray' object has no attribute 'rfind'

	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:193)
	at org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)
	at org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
17/05/11 23:25:33 INFO BlockManager: Found block rdd_19_0 locally
17/05/11 23:25:33 INFO BlockManager: Found block rdd_19_1 locally
17/05/11 23:25:33 ERROR Executor: Exception in task 2.2 in stage 18.0 (TID 64)
org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/python/lib/pyspark.zip/pyspark/worker.py", line 174, in main
    process()
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/python/lib/pyspark.zip/pyspark/worker.py", line 169, in process
    serializer.dump_stream(func(split_index, iterator), outfile)
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/python/lib/pyspark.zip/pyspark/serializers.py", line 268, in dump_stream
    vs = list(itertools.islice(iterator, batch))
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/python/lib/pyspark.zip/pyspark/rdd.py", line 833, in func
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/SparkScripts/es_scatter.py", line 119, in snapPop
    counter = lastHost[lastHost[lastHost.rfind('.'):].rfind('.'):].rfind('.')
AttributeError: 'numpy.ndarray' object has no attribute 'rfind'

	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:193)
	at org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)
	at org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
17/05/11 23:25:33 INFO CoarseGrainedExecutorBackend: Got assigned task 68
17/05/11 23:25:33 INFO Executor: Running task 4.2 in stage 18.0 (TID 68)
17/05/11 23:25:33 INFO BlockManager: Found block rdd_19_4 locally
17/05/11 23:25:33 INFO CoarseGrainedExecutorBackend: Got assigned task 69
17/05/11 23:25:33 INFO Executor: Running task 2.3 in stage 18.0 (TID 69)
17/05/11 23:25:33 INFO BlockManager: Found block rdd_19_2 locally
17/05/11 23:25:33 ERROR Executor: Exception in task 3.2 in stage 18.0 (TID 66)
org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/python/lib/pyspark.zip/pyspark/worker.py", line 174, in main
    process()
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/python/lib/pyspark.zip/pyspark/worker.py", line 169, in process
    serializer.dump_stream(func(split_index, iterator), outfile)
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/python/lib/pyspark.zip/pyspark/serializers.py", line 268, in dump_stream
    vs = list(itertools.islice(iterator, batch))
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/python/lib/pyspark.zip/pyspark/rdd.py", line 833, in func
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/SparkScripts/es_scatter.py", line 119, in snapPop
    counter = lastHost[lastHost[lastHost.rfind('.'):].rfind('.'):].rfind('.')
AttributeError: 'numpy.ndarray' object has no attribute 'rfind'

	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:193)
	at org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)
	at org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
17/05/11 23:25:33 ERROR Executor: Exception in task 0.2 in stage 18.0 (TID 65)
org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/python/lib/pyspark.zip/pyspark/worker.py", line 174, in main
    process()
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/python/lib/pyspark.zip/pyspark/worker.py", line 169, in process
    serializer.dump_stream(func(split_index, iterator), outfile)
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/python/lib/pyspark.zip/pyspark/serializers.py", line 268, in dump_stream
    vs = list(itertools.islice(iterator, batch))
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/python/lib/pyspark.zip/pyspark/rdd.py", line 833, in func
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/SparkScripts/es_scatter.py", line 119, in snapPop
    counter = lastHost[lastHost[lastHost.rfind('.'):].rfind('.'):].rfind('.')
AttributeError: 'numpy.ndarray' object has no attribute 'rfind'

	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:193)
	at org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)
	at org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
17/05/11 23:25:33 ERROR Executor: Exception in task 4.2 in stage 18.0 (TID 68)
org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/python/lib/pyspark.zip/pyspark/worker.py", line 174, in main
    process()
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/python/lib/pyspark.zip/pyspark/worker.py", line 169, in process
    serializer.dump_stream(func(split_index, iterator), outfile)
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/python/lib/pyspark.zip/pyspark/serializers.py", line 268, in dump_stream
    vs = list(itertools.islice(iterator, batch))
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/python/lib/pyspark.zip/pyspark/rdd.py", line 833, in func
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/SparkScripts/es_scatter.py", line 119, in snapPop
    counter = lastHost[lastHost[lastHost.rfind('.'):].rfind('.'):].rfind('.')
AttributeError: 'numpy.ndarray' object has no attribute 'rfind'

	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:193)
	at org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)
	at org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
17/05/11 23:25:33 ERROR Executor: Exception in task 1.2 in stage 18.0 (TID 67)
org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/python/lib/pyspark.zip/pyspark/worker.py", line 174, in main
    process()
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/python/lib/pyspark.zip/pyspark/worker.py", line 169, in process
    serializer.dump_stream(func(split_index, iterator), outfile)
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/python/lib/pyspark.zip/pyspark/serializers.py", line 268, in dump_stream
    vs = list(itertools.islice(iterator, batch))
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/python/lib/pyspark.zip/pyspark/rdd.py", line 833, in func
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/SparkScripts/es_scatter.py", line 119, in snapPop
    counter = lastHost[lastHost[lastHost.rfind('.'):].rfind('.'):].rfind('.')
AttributeError: 'numpy.ndarray' object has no attribute 'rfind'

	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:193)
	at org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)
	at org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
17/05/11 23:25:33 INFO CoarseGrainedExecutorBackend: Got assigned task 70
17/05/11 23:25:33 INFO Executor: Running task 3.3 in stage 18.0 (TID 70)
17/05/11 23:25:33 INFO CoarseGrainedExecutorBackend: Got assigned task 71
17/05/11 23:25:33 INFO Executor: Running task 0.3 in stage 18.0 (TID 71)
17/05/11 23:25:33 INFO BlockManager: Found block rdd_19_3 locally
17/05/11 23:25:33 INFO CoarseGrainedExecutorBackend: Got assigned task 72
17/05/11 23:25:33 INFO Executor: Running task 4.3 in stage 18.0 (TID 72)
17/05/11 23:25:33 INFO CoarseGrainedExecutorBackend: Got assigned task 73
17/05/11 23:25:33 INFO BlockManager: Found block rdd_19_0 locally
17/05/11 23:25:33 INFO Executor: Running task 1.3 in stage 18.0 (TID 73)
17/05/11 23:25:33 INFO BlockManager: Found block rdd_19_4 locally
17/05/11 23:25:33 INFO BlockManager: Found block rdd_19_1 locally
17/05/11 23:25:33 ERROR Executor: Exception in task 2.3 in stage 18.0 (TID 69)
org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/python/lib/pyspark.zip/pyspark/worker.py", line 174, in main
    process()
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/python/lib/pyspark.zip/pyspark/worker.py", line 169, in process
    serializer.dump_stream(func(split_index, iterator), outfile)
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/python/lib/pyspark.zip/pyspark/serializers.py", line 268, in dump_stream
    vs = list(itertools.islice(iterator, batch))
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/python/lib/pyspark.zip/pyspark/rdd.py", line 833, in func
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/SparkScripts/es_scatter.py", line 119, in snapPop
    counter = lastHost[lastHost[lastHost.rfind('.'):].rfind('.'):].rfind('.')
AttributeError: 'numpy.ndarray' object has no attribute 'rfind'

	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:193)
	at org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)
	at org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
17/05/11 23:25:33 ERROR Executor: Exception in task 3.3 in stage 18.0 (TID 70)
org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/python/lib/pyspark.zip/pyspark/worker.py", line 174, in main
    process()
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/python/lib/pyspark.zip/pyspark/worker.py", line 169, in process
    serializer.dump_stream(func(split_index, iterator), outfile)
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/python/lib/pyspark.zip/pyspark/serializers.py", line 268, in dump_stream
    vs = list(itertools.islice(iterator, batch))
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/python/lib/pyspark.zip/pyspark/rdd.py", line 833, in func
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/SparkScripts/es_scatter.py", line 119, in snapPop
    counter = lastHost[lastHost[lastHost.rfind('.'):].rfind('.'):].rfind('.')
AttributeError: 'numpy.ndarray' object has no attribute 'rfind'

	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:193)
	at org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)
	at org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
17/05/11 23:25:33 ERROR Executor: Exception in task 1.3 in stage 18.0 (TID 73)
org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/python/lib/pyspark.zip/pyspark/worker.py", line 174, in main
    process()
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/python/lib/pyspark.zip/pyspark/worker.py", line 169, in process
    serializer.dump_stream(func(split_index, iterator), outfile)
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/python/lib/pyspark.zip/pyspark/serializers.py", line 268, in dump_stream
    vs = list(itertools.islice(iterator, batch))
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/python/lib/pyspark.zip/pyspark/rdd.py", line 833, in func
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/SparkScripts/es_scatter.py", line 119, in snapPop
    counter = lastHost[lastHost[lastHost.rfind('.'):].rfind('.'):].rfind('.')
AttributeError: 'numpy.ndarray' object has no attribute 'rfind'

	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:193)
	at org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)
	at org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
17/05/11 23:25:33 INFO Executor: Executor is trying to kill task 0.3 in stage 18.0 (TID 71)
17/05/11 23:25:33 INFO Executor: Executor is trying to kill task 4.3 in stage 18.0 (TID 72)
17/05/11 23:25:33 INFO Executor: Executor killed task 0.3 in stage 18.0 (TID 71)
17/05/11 23:25:33 INFO Executor: Executor killed task 4.3 in stage 18.0 (TID 72)
17/05/11 23:25:33 INFO CoarseGrainedExecutorBackend: Driver commanded a shutdown
17/05/11 23:25:33 ERROR CoarseGrainedExecutorBackend: RECEIVED SIGNAL TERM
tdown
