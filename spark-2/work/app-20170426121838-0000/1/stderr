Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
17/04/26 12:18:39 INFO CoarseGrainedExecutorBackend: Started daemon with process name: 199731@c0405.crane.hcc.unl.edu
17/04/26 12:18:39 INFO SignalUtils: Registered signal handler for TERM
17/04/26 12:18:39 INFO SignalUtils: Registered signal handler for HUP
17/04/26 12:18:39 INFO SignalUtils: Registered signal handler for INT
17/04/26 12:18:40 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/04/26 12:18:40 INFO SecurityManager: Changing view acls to: jdixon
17/04/26 12:18:40 INFO SecurityManager: Changing modify acls to: jdixon
17/04/26 12:18:40 INFO SecurityManager: Changing view acls groups to: 
17/04/26 12:18:40 INFO SecurityManager: Changing modify acls groups to: 
17/04/26 12:18:40 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(jdixon); groups with view permissions: Set(); users  with modify permissions: Set(jdixon); groups with modify permissions: Set()
17/04/26 12:18:40 INFO TransportClientFactory: Successfully created connection to /10.138.4.3:38455 after 78 ms (0 ms spent in bootstraps)
17/04/26 12:18:40 INFO SecurityManager: Changing view acls to: jdixon
17/04/26 12:18:40 INFO SecurityManager: Changing modify acls to: jdixon
17/04/26 12:18:40 INFO SecurityManager: Changing view acls groups to: 
17/04/26 12:18:40 INFO SecurityManager: Changing modify acls groups to: 
17/04/26 12:18:40 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(jdixon); groups with view permissions: Set(); users  with modify permissions: Set(jdixon); groups with modify permissions: Set()
17/04/26 12:18:41 INFO TransportClientFactory: Successfully created connection to /10.138.4.3:38455 after 1 ms (0 ms spent in bootstraps)
17/04/26 12:18:41 INFO DiskBlockManager: Created local directory at /lustre/work/swanson/jdixon/tmp/spark-62348b4b-591f-45eb-92d7-f4d8d29b9b1f/executor-2a8f6ddf-0800-493a-9478-ec275d6c063e/blockmgr-33059c75-3398-4f11-9d48-2ac027413985
17/04/26 12:18:41 INFO MemoryStore: MemoryStore started with capacity 912.3 MB
17/04/26 12:18:41 INFO CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@10.138.4.3:38455
17/04/26 12:18:41 INFO WorkerWatcher: Connecting to worker spark://Worker@10.138.4.5:42609
17/04/26 12:18:41 INFO TransportClientFactory: Successfully created connection to /10.138.4.5:42609 after 1 ms (0 ms spent in bootstraps)
17/04/26 12:18:41 INFO WorkerWatcher: Successfully connected to spark://Worker@10.138.4.5:42609
17/04/26 12:18:41 INFO CoarseGrainedExecutorBackend: Successfully registered with driver
17/04/26 12:18:41 INFO Executor: Starting executor ID 1 on host 10.138.4.5
17/04/26 12:18:41 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 35875.
17/04/26 12:18:41 INFO NettyBlockTransferService: Server created on 10.138.4.5:35875
17/04/26 12:18:41 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
17/04/26 12:18:41 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(1, 10.138.4.5, 35875, None)
17/04/26 12:18:41 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(1, 10.138.4.5, 35875, None)
17/04/26 12:18:41 INFO BlockManager: Initialized BlockManager: BlockManagerId(1, 10.138.4.5, 35875, None)
17/04/26 12:18:41 INFO CoarseGrainedExecutorBackend: Got assigned task 0
17/04/26 12:18:41 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
17/04/26 12:18:41 INFO Executor: Fetching spark://10.138.4.3:38455/files/es_scatter.py with timestamp 1493227117947
17/04/26 12:18:41 INFO TransportClientFactory: Successfully created connection to /10.138.4.3:38455 after 1 ms (0 ms spent in bootstraps)
17/04/26 12:18:41 INFO Utils: Fetching spark://10.138.4.3:38455/files/es_scatter.py to /lustre/work/swanson/jdixon/tmp/spark-62348b4b-591f-45eb-92d7-f4d8d29b9b1f/executor-2a8f6ddf-0800-493a-9478-ec275d6c063e/spark-ede2b170-f26e-4468-8673-7d0048ca7ef9/fetchFileTemp8665268689344367964.tmp
17/04/26 12:18:41 INFO Utils: Copying /lustre/work/swanson/jdixon/tmp/spark-62348b4b-591f-45eb-92d7-f4d8d29b9b1f/executor-2a8f6ddf-0800-493a-9478-ec275d6c063e/spark-ede2b170-f26e-4468-8673-7d0048ca7ef9/-17081606971493227117947_cache to /lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/work/app-20170426121838-0000/1/./es_scatter.py
17/04/26 12:18:41 INFO Executor: Fetching spark://10.138.4.3:38455/jars/elasticsearch-hadoop-6.0.0.BUILD.SNAPSHOT.jar with timestamp 1493227117623
17/04/26 12:18:41 INFO Utils: Fetching spark://10.138.4.3:38455/jars/elasticsearch-hadoop-6.0.0.BUILD.SNAPSHOT.jar to /lustre/work/swanson/jdixon/tmp/spark-62348b4b-591f-45eb-92d7-f4d8d29b9b1f/executor-2a8f6ddf-0800-493a-9478-ec275d6c063e/spark-ede2b170-f26e-4468-8673-7d0048ca7ef9/fetchFileTemp2872319296011368319.tmp
17/04/26 12:18:41 INFO Utils: Copying /lustre/work/swanson/jdixon/tmp/spark-62348b4b-591f-45eb-92d7-f4d8d29b9b1f/executor-2a8f6ddf-0800-493a-9478-ec275d6c063e/spark-ede2b170-f26e-4468-8673-7d0048ca7ef9/20638510571493227117623_cache to /lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/work/app-20170426121838-0000/1/./elasticsearch-hadoop-6.0.0.BUILD.SNAPSHOT.jar
17/04/26 12:18:41 INFO Executor: Adding file:/lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/work/app-20170426121838-0000/1/./elasticsearch-hadoop-6.0.0.BUILD.SNAPSHOT.jar to class loader
17/04/26 12:18:41 INFO TorrentBroadcast: Started reading broadcast variable 2
17/04/26 12:18:42 INFO TransportClientFactory: Successfully created connection to /10.138.4.3:41273 after 1 ms (0 ms spent in bootstraps)
17/04/26 12:18:42 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 1790.0 B, free 912.3 MB)
17/04/26 12:18:42 INFO TorrentBroadcast: Reading broadcast variable 2 took 172 ms
17/04/26 12:18:42 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 2.9 KB, free 912.3 MB)
17/04/26 12:18:42 INFO NewHadoopRDD: Input split: org.elasticsearch.hadoop.mr.EsInputFormat$EsInputSplit@3c044e9f
17/04/26 12:18:42 INFO TorrentBroadcast: Started reading broadcast variable 0
17/04/26 12:18:42 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.2 KB, free 912.3 MB)
17/04/26 12:18:42 INFO TorrentBroadcast: Reading broadcast variable 0 took 17 ms
17/04/26 12:18:42 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 294.6 KB, free 912.0 MB)
17/04/26 12:18:42 INFO deprecation: mapred.mapoutput.value.class is deprecated. Instead, use mapreduce.map.output.value.class
17/04/26 12:18:43 INFO deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
17/04/26 12:18:43 INFO deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id
17/04/26 12:18:43 WARN EsInputFormat: Cannot determine task id...
17/04/26 12:18:43 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 4589 bytes result sent to driver
17/04/26 12:18:43 INFO CoarseGrainedExecutorBackend: Got assigned task 1
17/04/26 12:18:43 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
17/04/26 12:18:43 INFO CoarseGrainedExecutorBackend: Got assigned task 3
17/04/26 12:18:43 INFO Executor: Running task 2.0 in stage 1.0 (TID 3)
17/04/26 12:18:43 INFO CoarseGrainedExecutorBackend: Got assigned task 5
17/04/26 12:18:43 INFO Executor: Running task 4.0 in stage 1.0 (TID 5)
17/04/26 12:18:43 INFO TorrentBroadcast: Started reading broadcast variable 3
17/04/26 12:18:43 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 6.5 KB, free 912.0 MB)
17/04/26 12:18:43 INFO TorrentBroadcast: Reading broadcast variable 3 took 20 ms
17/04/26 12:18:43 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 10.5 KB, free 912.0 MB)
17/04/26 12:18:43 INFO NewHadoopRDD: Input split: org.elasticsearch.hadoop.mr.EsInputFormat$EsInputSplit@5919d25d
17/04/26 12:18:43 INFO NewHadoopRDD: Input split: org.elasticsearch.hadoop.mr.EsInputFormat$EsInputSplit@2e42055e
17/04/26 12:18:43 INFO NewHadoopRDD: Input split: org.elasticsearch.hadoop.mr.EsInputFormat$EsInputSplit@706e760b
17/04/26 12:18:43 WARN EsInputFormat: Cannot determine task id...
17/04/26 12:18:43 WARN EsInputFormat: Cannot determine task id...
17/04/26 12:18:43 WARN EsInputFormat: Cannot determine task id...
17/04/26 12:18:48 INFO PythonRunner: Times: total = 4640, boot = 941, init = 352, finish = 3347
17/04/26 12:18:48 INFO MemoryStore: Block rdd_3_2 stored as bytes in memory (estimated size 6.4 MB, free 905.5 MB)
17/04/26 12:18:48 INFO PythonRunner: Times: total = 4663, boot = 925, init = 374, finish = 3364
17/04/26 12:18:48 INFO PythonRunner: Times: total = 4695, boot = 930, init = 321, finish = 3444
17/04/26 12:18:48 INFO MemoryStore: Block rdd_3_4 stored as bytes in memory (estimated size 6.5 MB, free 899.1 MB)
17/04/26 12:18:48 INFO MemoryStore: Block rdd_3_0 stored as bytes in memory (estimated size 6.5 MB, free 892.6 MB)
17/04/26 12:18:48 INFO PythonRunner: Times: total = 227, boot = -16, init = 19, finish = 224
17/04/26 12:18:48 INFO Executor: Finished task 2.0 in stage 1.0 (TID 3). 2558 bytes result sent to driver
17/04/26 12:18:48 INFO PythonRunner: Times: total = 277, boot = -44, init = 50, finish = 271
17/04/26 12:18:48 INFO PythonRunner: Times: total = 284, boot = 8, init = 15, finish = 261
17/04/26 12:18:48 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 2678 bytes result sent to driver
17/04/26 12:18:48 INFO Executor: Finished task 4.0 in stage 1.0 (TID 5). 2471 bytes result sent to driver
17/04/26 12:18:51 INFO CoarseGrainedExecutorBackend: Got assigned task 6
17/04/26 12:18:51 INFO Executor: Running task 0.0 in stage 2.0 (TID 6)
17/04/26 12:18:51 INFO CoarseGrainedExecutorBackend: Got assigned task 8
17/04/26 12:18:51 INFO Executor: Running task 2.0 in stage 2.0 (TID 8)
17/04/26 12:18:51 INFO CoarseGrainedExecutorBackend: Got assigned task 10
17/04/26 12:18:51 INFO Executor: Running task 3.0 in stage 2.0 (TID 10)
17/04/26 12:18:51 INFO MapOutputTrackerWorker: Updating epoch to 1 and clearing cache
17/04/26 12:18:51 INFO TorrentBroadcast: Started reading broadcast variable 4
17/04/26 12:18:51 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 4.5 KB, free 892.6 MB)
17/04/26 12:18:51 INFO TorrentBroadcast: Reading broadcast variable 4 took 10 ms
17/04/26 12:18:51 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 7.1 KB, free 892.6 MB)
17/04/26 12:18:51 INFO MapOutputTrackerWorker: Don't have map outputs for shuffle 0, fetching them
17/04/26 12:18:51 INFO MapOutputTrackerWorker: Don't have map outputs for shuffle 0, fetching them
17/04/26 12:18:51 INFO MapOutputTrackerWorker: Don't have map outputs for shuffle 0, fetching them
17/04/26 12:18:51 INFO MapOutputTrackerWorker: Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@10.138.4.3:38455)
17/04/26 12:18:51 INFO MapOutputTrackerWorker: Got the output locations
17/04/26 12:18:51 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 5 blocks
17/04/26 12:18:51 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/04/26 12:18:51 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/04/26 12:18:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
17/04/26 12:18:51 INFO TransportClientFactory: Successfully created connection to /10.138.4.4:35842 after 4 ms (0 ms spent in bootstraps)
17/04/26 12:18:51 INFO ShuffleBlockFetcherIterator: Started 1 remote fetches in 14 ms
17/04/26 12:18:51 INFO ShuffleBlockFetcherIterator: Started 1 remote fetches in 14 ms
17/04/26 12:18:51 INFO PythonRunner: Times: total = 52, boot = -3201, init = 3252, finish = 1
17/04/26 12:18:51 INFO Executor: Finished task 3.0 in stage 2.0 (TID 10). 2091 bytes result sent to driver
17/04/26 12:18:51 INFO PythonRunner: Times: total = 50, boot = -3120, init = 3169, finish = 1
17/04/26 12:18:51 INFO Executor: Finished task 0.0 in stage 2.0 (TID 6). 2802 bytes result sent to driver
17/04/26 12:18:52 INFO PythonRunner: Times: total = 58, boot = -3127, init = 3184, finish = 1
17/04/26 12:18:52 INFO Executor: Finished task 2.0 in stage 2.0 (TID 8). 2192 bytes result sent to driver
17/04/26 12:18:52 INFO CoarseGrainedExecutorBackend: Got assigned task 11
17/04/26 12:18:52 INFO Executor: Running task 0.0 in stage 3.0 (TID 11)
17/04/26 12:18:52 INFO CoarseGrainedExecutorBackend: Got assigned task 13
17/04/26 12:18:52 INFO Executor: Running task 2.0 in stage 3.0 (TID 13)
17/04/26 12:18:52 INFO CoarseGrainedExecutorBackend: Got assigned task 15
17/04/26 12:18:52 INFO Executor: Running task 4.0 in stage 3.0 (TID 15)
17/04/26 12:18:52 INFO TorrentBroadcast: Started reading broadcast variable 5
17/04/26 12:18:52 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 6.5 KB, free 892.5 MB)
17/04/26 12:18:52 INFO TorrentBroadcast: Reading broadcast variable 5 took 13 ms
17/04/26 12:18:52 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 10.5 KB, free 892.5 MB)
17/04/26 12:18:52 INFO BlockManager: Found block rdd_3_4 locally
17/04/26 12:18:52 INFO BlockManager: Found block rdd_3_0 locally
17/04/26 12:18:52 INFO BlockManager: Found block rdd_3_2 locally
17/04/26 12:18:52 INFO PythonRunner: Times: total = 218, boot = -198, init = 200, finish = 216
17/04/26 12:18:52 INFO PythonRunner: Times: total = 239, boot = -190, init = 192, finish = 237
17/04/26 12:18:52 INFO Executor: Finished task 4.0 in stage 3.0 (TID 15). 2039 bytes result sent to driver
17/04/26 12:18:52 INFO Executor: Finished task 0.0 in stage 3.0 (TID 11). 2570 bytes result sent to driver
17/04/26 12:18:52 INFO PythonRunner: Times: total = 273, boot = -186, init = 213, finish = 246
17/04/26 12:18:52 INFO Executor: Finished task 2.0 in stage 3.0 (TID 13). 2039 bytes result sent to driver
17/04/26 12:18:52 INFO CoarseGrainedExecutorBackend: Got assigned task 17
17/04/26 12:18:52 INFO Executor: Running task 2.0 in stage 4.0 (TID 17)
17/04/26 12:18:52 INFO CoarseGrainedExecutorBackend: Got assigned task 19
17/04/26 12:18:52 INFO Executor: Running task 3.0 in stage 4.0 (TID 19)
17/04/26 12:18:52 INFO MapOutputTrackerWorker: Updating epoch to 2 and clearing cache
17/04/26 12:18:52 INFO TorrentBroadcast: Started reading broadcast variable 6
17/04/26 12:18:52 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 4.5 KB, free 892.5 MB)
17/04/26 12:18:52 INFO TorrentBroadcast: Reading broadcast variable 6 took 16 ms
17/04/26 12:18:52 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 7.1 KB, free 892.5 MB)
17/04/26 12:18:52 INFO MapOutputTrackerWorker: Don't have map outputs for shuffle 1, fetching them
17/04/26 12:18:52 INFO MapOutputTrackerWorker: Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@10.138.4.3:38455)
17/04/26 12:18:52 INFO MapOutputTrackerWorker: Don't have map outputs for shuffle 1, fetching them
17/04/26 12:18:52 INFO MapOutputTrackerWorker: Got the output locations
17/04/26 12:18:52 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 5 blocks
17/04/26 12:18:52 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/04/26 12:18:52 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/04/26 12:18:52 INFO ShuffleBlockFetcherIterator: Started 1 remote fetches in 1 ms
17/04/26 12:18:52 INFO PythonRunner: Times: total = 1, boot = -246, init = 247, finish = 0
17/04/26 12:18:52 INFO Executor: Finished task 3.0 in stage 4.0 (TID 19). 2622 bytes result sent to driver
17/04/26 12:18:52 INFO PythonRunner: Times: total = 6, boot = -223, init = 229, finish = 0
17/04/26 12:18:52 INFO Executor: Finished task 2.0 in stage 4.0 (TID 17). 2175 bytes result sent to driver
17/04/26 12:18:52 INFO CoarseGrainedExecutorBackend: Got assigned task 22
17/04/26 12:18:52 INFO Executor: Running task 0.0 in stage 5.0 (TID 22)
17/04/26 12:18:52 INFO CoarseGrainedExecutorBackend: Got assigned task 24
17/04/26 12:18:52 INFO Executor: Running task 2.0 in stage 5.0 (TID 24)
17/04/26 12:18:52 INFO CoarseGrainedExecutorBackend: Got assigned task 25
17/04/26 12:18:52 INFO Executor: Running task 4.0 in stage 5.0 (TID 25)
17/04/26 12:18:52 INFO TorrentBroadcast: Started reading broadcast variable 7
17/04/26 12:18:52 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 6.5 KB, free 892.5 MB)
17/04/26 12:18:52 INFO TorrentBroadcast: Reading broadcast variable 7 took 21 ms
17/04/26 12:18:52 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 10.5 KB, free 892.5 MB)
17/04/26 12:18:52 INFO BlockManager: Found block rdd_3_4 locally
17/04/26 12:18:52 INFO BlockManager: Found block rdd_3_2 locally
17/04/26 12:18:52 INFO BlockManager: Found block rdd_3_0 locally
17/04/26 12:18:53 INFO PythonRunner: Times: total = 237, boot = -197, init = 205, finish = 229
17/04/26 12:18:53 INFO PythonRunner: Times: total = 213, boot = -188, init = 191, finish = 210
17/04/26 12:18:53 INFO PythonRunner: Times: total = 240, boot = -395, init = 397, finish = 238
17/04/26 12:18:53 INFO Executor: Finished task 0.0 in stage 5.0 (TID 22). 2570 bytes result sent to driver
17/04/26 12:18:53 INFO Executor: Finished task 2.0 in stage 5.0 (TID 24). 2039 bytes result sent to driver
17/04/26 12:18:53 INFO Executor: Finished task 4.0 in stage 5.0 (TID 25). 2039 bytes result sent to driver
17/04/26 12:18:53 INFO CoarseGrainedExecutorBackend: Got assigned task 27
17/04/26 12:18:53 INFO Executor: Running task 1.0 in stage 6.0 (TID 27)
17/04/26 12:18:53 INFO CoarseGrainedExecutorBackend: Got assigned task 29
17/04/26 12:18:53 INFO Executor: Running task 3.0 in stage 6.0 (TID 29)
17/04/26 12:18:53 INFO MapOutputTrackerWorker: Updating epoch to 3 and clearing cache
17/04/26 12:18:53 INFO TorrentBroadcast: Started reading broadcast variable 8
17/04/26 12:18:53 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 4.5 KB, free 892.5 MB)
17/04/26 12:18:53 INFO TorrentBroadcast: Reading broadcast variable 8 took 17 ms
17/04/26 12:18:53 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 7.1 KB, free 892.5 MB)
17/04/26 12:18:53 INFO MapOutputTrackerWorker: Don't have map outputs for shuffle 2, fetching them
17/04/26 12:18:53 INFO MapOutputTrackerWorker: Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@10.138.4.3:38455)
17/04/26 12:18:53 INFO MapOutputTrackerWorker: Don't have map outputs for shuffle 2, fetching them
17/04/26 12:18:53 INFO MapOutputTrackerWorker: Got the output locations
17/04/26 12:18:53 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/04/26 12:18:53 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/04/26 12:18:53 INFO ShuffleBlockFetcherIterator: Started 1 remote fetches in 0 ms
17/04/26 12:18:53 INFO ShuffleBlockFetcherIterator: Started 1 remote fetches in 1 ms
17/04/26 12:18:53 INFO PythonRunner: Times: total = 10, boot = -224, init = 232, finish = 2
17/04/26 12:18:53 INFO Executor: Finished task 3.0 in stage 6.0 (TID 29). 6240 bytes result sent to driver
17/04/26 12:18:53 INFO PythonRunner: Times: total = 48, boot = -214, init = 261, finish = 1
17/04/26 12:18:53 INFO Executor: Finished task 1.0 in stage 6.0 (TID 27). 5676 bytes result sent to driver
17/04/26 12:18:53 INFO CoarseGrainedExecutorBackend: Got assigned task 31
17/04/26 12:18:53 INFO Executor: Running task 0.0 in stage 7.0 (TID 31)
17/04/26 12:18:53 INFO TorrentBroadcast: Started reading broadcast variable 9
17/04/26 12:18:53 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 4.1 KB, free 892.5 MB)
17/04/26 12:18:53 INFO TorrentBroadcast: Reading broadcast variable 9 took 12 ms
17/04/26 12:18:53 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 7.7 KB, free 892.5 MB)
17/04/26 12:18:53 INFO BlockManager: Found block rdd_3_0 locally
17/04/26 12:18:53 INFO PythonRunner: Times: total = 182, boot = -441, init = 442, finish = 181
17/04/26 12:18:53 INFO MemoryStore: Block rdd_19_0 stored as bytes in memory (estimated size 477.5 KB, free 892.0 MB)
17/04/26 12:18:53 INFO PythonRunner: Times: total = 1, boot = -395, init = 396, finish = 0
17/04/26 12:18:53 WARN Executor: 1 block locks were not released by TID = 31:
[rdd_19_0]
17/04/26 12:18:53 INFO Executor: Finished task 0.0 in stage 7.0 (TID 31). 4592 bytes result sent to driver
17/04/26 12:18:53 INFO CoarseGrainedExecutorBackend: Got assigned task 32
17/04/26 12:18:53 INFO Executor: Running task 0.0 in stage 8.0 (TID 32)
17/04/26 12:18:53 INFO TorrentBroadcast: Started reading broadcast variable 10
17/04/26 12:18:53 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 4.5 KB, free 892.0 MB)
17/04/26 12:18:53 INFO TorrentBroadcast: Reading broadcast variable 10 took 9 ms
17/04/26 12:18:53 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 8.4 KB, free 892.0 MB)
17/04/26 12:18:53 INFO BlockManager: Found block rdd_19_0 locally
17/04/26 12:18:53 INFO PythonRunner: Times: total = 14, boot = -468, init = 469, finish = 13
17/04/26 12:18:53 INFO Executor: Finished task 0.0 in stage 8.0 (TID 32). 2230 bytes result sent to driver
17/04/26 12:18:53 INFO CoarseGrainedExecutorBackend: Got assigned task 33
17/04/26 12:18:53 INFO Executor: Running task 1.0 in stage 9.0 (TID 33)
17/04/26 12:18:53 INFO CoarseGrainedExecutorBackend: Got assigned task 35
17/04/26 12:18:53 INFO Executor: Running task 3.0 in stage 9.0 (TID 35)
17/04/26 12:18:53 INFO TorrentBroadcast: Started reading broadcast variable 11
17/04/26 12:18:53 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 4.5 KB, free 892.0 MB)
17/04/26 12:18:53 INFO TorrentBroadcast: Reading broadcast variable 11 took 11 ms
17/04/26 12:18:53 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 8.4 KB, free 892.0 MB)
17/04/26 12:18:53 INFO BlockManager: Found block rdd_3_2 locally
17/04/26 12:18:53 INFO BlockManager: Found block rdd_3_4 locally
17/04/26 12:18:54 INFO PythonRunner: Times: total = 203, boot = -210, init = 211, finish = 202
17/04/26 12:18:54 INFO MemoryStore: Block rdd_19_2 stored as bytes in memory (estimated size 466.6 KB, free 891.5 MB)
17/04/26 12:18:54 INFO PythonRunner: Times: total = 227, boot = -85, init = 120, finish = 192
17/04/26 12:18:54 INFO MemoryStore: Block rdd_19_4 stored as bytes in memory (estimated size 460.9 KB, free 891.1 MB)
17/04/26 12:18:54 INFO PythonRunner: Times: total = 14, boot = -2, init = 3, finish = 13
17/04/26 12:18:54 INFO Executor: Finished task 1.0 in stage 9.0 (TID 33). 2344 bytes result sent to driver
17/04/26 12:18:54 INFO PythonRunner: Times: total = 44, boot = -8, init = 9, finish = 43
17/04/26 12:18:54 INFO Executor: Finished task 3.0 in stage 9.0 (TID 35). 2137 bytes result sent to driver
17/04/26 12:18:54 INFO CoarseGrainedExecutorBackend: Got assigned task 37
17/04/26 12:18:54 INFO Executor: Running task 0.0 in stage 10.0 (TID 37)
17/04/26 12:18:54 INFO TorrentBroadcast: Started reading broadcast variable 12
17/04/26 12:18:54 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 4.5 KB, free 891.1 MB)
17/04/26 12:18:54 INFO TorrentBroadcast: Reading broadcast variable 12 took 13 ms
17/04/26 12:18:54 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 8.4 KB, free 891.1 MB)
17/04/26 12:18:54 INFO BlockManager: Found block rdd_19_0 locally
17/04/26 12:18:54 INFO PythonRunner: Times: total = 14, boot = -170, init = 171, finish = 13
17/04/26 12:18:54 INFO Executor: Finished task 0.0 in stage 10.0 (TID 37). 2230 bytes result sent to driver
17/04/26 12:18:54 INFO CoarseGrainedExecutorBackend: Got assigned task 38
17/04/26 12:18:54 INFO Executor: Running task 1.0 in stage 11.0 (TID 38)
17/04/26 12:18:54 INFO CoarseGrainedExecutorBackend: Got assigned task 40
17/04/26 12:18:54 INFO Executor: Running task 3.0 in stage 11.0 (TID 40)
17/04/26 12:18:54 INFO TorrentBroadcast: Started reading broadcast variable 13
17/04/26 12:18:54 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 4.5 KB, free 891.1 MB)
17/04/26 12:18:54 INFO TorrentBroadcast: Reading broadcast variable 13 took 12 ms
17/04/26 12:18:54 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 8.4 KB, free 891.1 MB)
17/04/26 12:18:54 INFO BlockManager: Found block rdd_19_2 locally
17/04/26 12:18:54 INFO BlockManager: Found block rdd_19_4 locally
17/04/26 12:18:54 INFO PythonRunner: Times: total = 16, boot = -197, init = 198, finish = 15
17/04/26 12:18:54 INFO PythonRunner: Times: total = 16, boot = -64, init = 65, finish = 15
17/04/26 12:18:54 INFO Executor: Finished task 1.0 in stage 11.0 (TID 38). 2230 bytes result sent to driver
17/04/26 12:18:54 INFO Executor: Finished task 3.0 in stage 11.0 (TID 40). 1699 bytes result sent to driver
17/04/26 12:18:54 INFO CoarseGrainedExecutorBackend: Got assigned task 42
17/04/26 12:18:54 INFO Executor: Running task 0.0 in stage 12.0 (TID 42)
17/04/26 12:18:54 INFO TorrentBroadcast: Started reading broadcast variable 14
17/04/26 12:18:54 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 4.5 KB, free 891.1 MB)
17/04/26 12:18:54 INFO TorrentBroadcast: Reading broadcast variable 14 took 10 ms
17/04/26 12:18:54 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 8.4 KB, free 891.0 MB)
17/04/26 12:18:54 INFO BlockManager: Found block rdd_19_0 locally
17/04/26 12:18:54 INFO PythonRunner: Times: total = 1, boot = -88, init = 89, finish = 0
17/04/26 12:18:54 WARN Executor: 1 block locks were not released by TID = 42:
[rdd_19_0]
17/04/26 12:18:54 INFO Executor: Finished task 0.0 in stage 12.0 (TID 42). 4478 bytes result sent to driver
17/04/26 12:18:54 INFO CoarseGrainedExecutorBackend: Got assigned task 44
17/04/26 12:18:54 INFO Executor: Running task 0.0 in stage 13.0 (TID 44)
17/04/26 12:18:54 INFO CoarseGrainedExecutorBackend: Got assigned task 46
17/04/26 12:18:54 INFO Executor: Running task 2.0 in stage 13.0 (TID 46)
17/04/26 12:18:54 INFO TorrentBroadcast: Started reading broadcast variable 15
17/04/26 12:18:54 INFO CoarseGrainedExecutorBackend: Got assigned task 47
17/04/26 12:18:54 INFO Executor: Running task 4.0 in stage 13.0 (TID 47)
17/04/26 12:18:54 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 5.0 KB, free 891.0 MB)
17/04/26 12:18:54 INFO TorrentBroadcast: Reading broadcast variable 15 took 12 ms
17/04/26 12:18:54 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 9.0 KB, free 891.0 MB)
17/04/26 12:18:54 INFO BlockManager: Found block rdd_19_4 locally
17/04/26 12:18:54 INFO BlockManager: Found block rdd_19_2 locally
17/04/26 12:18:54 INFO BlockManager: Found block rdd_19_0 locally
17/04/26 12:18:54 ERROR Executor: Exception in task 2.0 in stage 13.0 (TID 46)
org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/python/lib/pyspark.zip/pyspark/worker.py", line 174, in main
    process()
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/python/lib/pyspark.zip/pyspark/worker.py", line 169, in process
    serializer.dump_stream(func(split_index, iterator), outfile)
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/python/lib/pyspark.zip/pyspark/serializers.py", line 268, in dump_stream
    vs = list(itertools.islice(iterator, batch))
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/python/lib/pyspark.zip/pyspark/rdd.py", line 833, in func
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/SparkScripts/es_scatter.py", line 117, in hccReduce
    temp={'CpuEff' : np.append(accum["CpuEff"], \
KeyError: 'CpuEff'

	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:193)
	at org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)
	at org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
17/04/26 12:18:54 ERROR Executor: Exception in task 4.0 in stage 13.0 (TID 47)
org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/python/lib/pyspark.zip/pyspark/worker.py", line 174, in main
    process()
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/python/lib/pyspark.zip/pyspark/worker.py", line 169, in process
    serializer.dump_stream(func(split_index, iterator), outfile)
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/python/lib/pyspark.zip/pyspark/serializers.py", line 268, in dump_stream
    vs = list(itertools.islice(iterator, batch))
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/python/lib/pyspark.zip/pyspark/rdd.py", line 833, in func
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/SparkScripts/es_scatter.py", line 117, in hccReduce
    temp={'CpuEff' : np.append(accum["CpuEff"], \
KeyError: 'CpuEff'

	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:193)
	at org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)
	at org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
17/04/26 12:18:54 ERROR Executor: Exception in task 0.0 in stage 13.0 (TID 44)
org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/python/lib/pyspark.zip/pyspark/worker.py", line 174, in main
    process()
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/python/lib/pyspark.zip/pyspark/worker.py", line 169, in process
    serializer.dump_stream(func(split_index, iterator), outfile)
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/python/lib/pyspark.zip/pyspark/serializers.py", line 268, in dump_stream
    vs = list(itertools.islice(iterator, batch))
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/python/lib/pyspark.zip/pyspark/rdd.py", line 833, in func
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/SparkScripts/es_scatter.py", line 117, in hccReduce
    temp={'CpuEff' : np.append(accum["CpuEff"], \
KeyError: 'CpuEff'

	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:193)
	at org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)
	at org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
17/04/26 12:18:54 INFO CoarseGrainedExecutorBackend: Got assigned task 48
17/04/26 12:18:54 INFO Executor: Running task 0.1 in stage 13.0 (TID 48)
17/04/26 12:18:54 INFO BlockManager: Found block rdd_19_0 locally
17/04/26 12:18:54 INFO CoarseGrainedExecutorBackend: Got assigned task 49
17/04/26 12:18:54 INFO Executor: Running task 4.1 in stage 13.0 (TID 49)
17/04/26 12:18:54 INFO CoarseGrainedExecutorBackend: Got assigned task 50
17/04/26 12:18:54 INFO Executor: Running task 2.1 in stage 13.0 (TID 50)
17/04/26 12:18:54 INFO BlockManager: Found block rdd_19_4 locally
17/04/26 12:18:54 INFO BlockManager: Found block rdd_19_2 locally
17/04/26 12:18:54 ERROR Executor: Exception in task 0.1 in stage 13.0 (TID 48)
org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/python/lib/pyspark.zip/pyspark/worker.py", line 174, in main
    process()
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/python/lib/pyspark.zip/pyspark/worker.py", line 169, in process
    serializer.dump_stream(func(split_index, iterator), outfile)
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/python/lib/pyspark.zip/pyspark/serializers.py", line 268, in dump_stream
    vs = list(itertools.islice(iterator, batch))
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/python/lib/pyspark.zip/pyspark/rdd.py", line 833, in func
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/SparkScripts/es_scatter.py", line 117, in hccReduce
    temp={'CpuEff' : np.append(accum["CpuEff"], \
KeyError: 'CpuEff'

	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:193)
	at org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)
	at org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
17/04/26 12:18:54 ERROR Executor: Exception in task 4.1 in stage 13.0 (TID 49)
org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/python/lib/pyspark.zip/pyspark/worker.py", line 174, in main
    process()
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/python/lib/pyspark.zip/pyspark/worker.py", line 169, in process
    serializer.dump_stream(func(split_index, iterator), outfile)
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/python/lib/pyspark.zip/pyspark/serializers.py", line 268, in dump_stream
    vs = list(itertools.islice(iterator, batch))
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/python/lib/pyspark.zip/pyspark/rdd.py", line 833, in func
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/SparkScripts/es_scatter.py", line 117, in hccReduce
    temp={'CpuEff' : np.append(accum["CpuEff"], \
KeyError: 'CpuEff'

	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:193)
	at org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)
	at org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
17/04/26 12:18:54 ERROR Executor: Exception in task 2.1 in stage 13.0 (TID 50)
org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/python/lib/pyspark.zip/pyspark/worker.py", line 174, in main
    process()
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/python/lib/pyspark.zip/pyspark/worker.py", line 169, in process
    serializer.dump_stream(func(split_index, iterator), outfile)
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/python/lib/pyspark.zip/pyspark/serializers.py", line 268, in dump_stream
    vs = list(itertools.islice(iterator, batch))
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/python/lib/pyspark.zip/pyspark/rdd.py", line 833, in func
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/SparkScripts/es_scatter.py", line 117, in hccReduce
    temp={'CpuEff' : np.append(accum["CpuEff"], \
KeyError: 'CpuEff'

	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:193)
	at org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)
	at org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
17/04/26 12:18:54 INFO CoarseGrainedExecutorBackend: Got assigned task 52
17/04/26 12:18:54 INFO Executor: Running task 1.1 in stage 13.0 (TID 52)
17/04/26 12:18:54 INFO CoarseGrainedExecutorBackend: Got assigned task 53
17/04/26 12:18:54 INFO Executor: Running task 4.2 in stage 13.0 (TID 53)
17/04/26 12:18:54 INFO CoarseGrainedExecutorBackend: Got assigned task 55
17/04/26 12:18:54 INFO CoarseGrainedExecutorBackend: Got assigned task 56
17/04/26 12:18:54 INFO BlockManager: Found block rdd_19_1 remotely
17/04/26 12:18:54 INFO Executor: Running task 2.2 in stage 13.0 (TID 55)
17/04/26 12:18:54 INFO BlockManager: Found block rdd_19_2 locally
17/04/26 12:18:54 INFO Executor: Running task 0.2 in stage 13.0 (TID 56)
17/04/26 12:18:54 INFO BlockManager: Found block rdd_19_4 locally
17/04/26 12:18:54 INFO BlockManager: Found block rdd_19_0 locally
17/04/26 12:18:54 ERROR Executor: Exception in task 1.1 in stage 13.0 (TID 52)
org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/python/lib/pyspark.zip/pyspark/worker.py", line 174, in main
    process()
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/python/lib/pyspark.zip/pyspark/worker.py", line 169, in process
    serializer.dump_stream(func(split_index, iterator), outfile)
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/python/lib/pyspark.zip/pyspark/serializers.py", line 268, in dump_stream
    vs = list(itertools.islice(iterator, batch))
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/python/lib/pyspark.zip/pyspark/rdd.py", line 833, in func
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/SparkScripts/es_scatter.py", line 117, in hccReduce
    temp={'CpuEff' : np.append(accum["CpuEff"], \
KeyError: 'CpuEff'

	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:193)
	at org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)
	at org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
17/04/26 12:18:54 ERROR Executor: Exception in task 0.2 in stage 13.0 (TID 56)
org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/python/lib/pyspark.zip/pyspark/worker.py", line 174, in main
    process()
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/python/lib/pyspark.zip/pyspark/worker.py", line 169, in process
    serializer.dump_stream(func(split_index, iterator), outfile)
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/python/lib/pyspark.zip/pyspark/serializers.py", line 268, in dump_stream
    vs = list(itertools.islice(iterator, batch))
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/python/lib/pyspark.zip/pyspark/rdd.py", line 833, in func
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/SparkScripts/es_scatter.py", line 117, in hccReduce
    temp={'CpuEff' : np.append(accum["CpuEff"], \
KeyError: 'CpuEff'

	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:193)
	at org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)
	at org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
17/04/26 12:18:54 INFO CoarseGrainedExecutorBackend: Got assigned task 57
17/04/26 12:18:54 INFO Executor: Running task 3.3 in stage 13.0 (TID 57)
17/04/26 12:18:54 INFO CoarseGrainedExecutorBackend: Got assigned task 59
17/04/26 12:18:54 INFO Executor: Running task 0.3 in stage 13.0 (TID 59)
17/04/26 12:18:54 ERROR Executor: Exception in task 2.2 in stage 13.0 (TID 55)
org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/python/lib/pyspark.zip/pyspark/worker.py", line 174, in main
    process()
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/python/lib/pyspark.zip/pyspark/worker.py", line 169, in process
    serializer.dump_stream(func(split_index, iterator), outfile)
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/python/lib/pyspark.zip/pyspark/serializers.py", line 268, in dump_stream
    vs = list(itertools.islice(iterator, batch))
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/python/lib/pyspark.zip/pyspark/rdd.py", line 833, in func
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/SparkScripts/es_scatter.py", line 117, in hccReduce
    temp={'CpuEff' : np.append(accum["CpuEff"], \
KeyError: 'CpuEff'

	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:193)
	at org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)
	at org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
17/04/26 12:18:54 INFO BlockManager: Found block rdd_19_0 locally
17/04/26 12:18:55 ERROR Executor: Exception in task 4.2 in stage 13.0 (TID 53)
org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/python/lib/pyspark.zip/pyspark/worker.py", line 174, in main
    process()
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/python/lib/pyspark.zip/pyspark/worker.py", line 169, in process
    serializer.dump_stream(func(split_index, iterator), outfile)
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/python/lib/pyspark.zip/pyspark/serializers.py", line 268, in dump_stream
    vs = list(itertools.islice(iterator, batch))
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/python/lib/pyspark.zip/pyspark/rdd.py", line 833, in func
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/SparkScripts/es_scatter.py", line 117, in hccReduce
    temp={'CpuEff' : np.append(accum["CpuEff"], \
KeyError: 'CpuEff'

	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:193)
	at org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)
	at org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
17/04/26 12:18:55 INFO CoarseGrainedExecutorBackend: Got assigned task 60
17/04/26 12:18:55 INFO Executor: Running task 2.3 in stage 13.0 (TID 60)
17/04/26 12:18:55 INFO BlockManager: Found block rdd_19_3 remotely
17/04/26 12:18:55 INFO CoarseGrainedExecutorBackend: Got assigned task 61
17/04/26 12:18:55 INFO Executor: Running task 4.3 in stage 13.0 (TID 61)
17/04/26 12:18:55 INFO BlockManager: Found block rdd_19_2 locally
17/04/26 12:18:55 INFO BlockManager: Found block rdd_19_4 locally
17/04/26 12:18:55 ERROR Executor: Exception in task 0.3 in stage 13.0 (TID 59)
org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/python/lib/pyspark.zip/pyspark/worker.py", line 174, in main
    process()
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/python/lib/pyspark.zip/pyspark/worker.py", line 169, in process
    serializer.dump_stream(func(split_index, iterator), outfile)
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/python/lib/pyspark.zip/pyspark/serializers.py", line 268, in dump_stream
    vs = list(itertools.islice(iterator, batch))
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/python/lib/pyspark.zip/pyspark/rdd.py", line 833, in func
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/SparkScripts/es_scatter.py", line 117, in hccReduce
    temp={'CpuEff' : np.append(accum["CpuEff"], \
KeyError: 'CpuEff'

	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:193)
	at org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)
	at org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
17/04/26 12:18:55 ERROR Executor: Exception in task 3.3 in stage 13.0 (TID 57)
org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/python/lib/pyspark.zip/pyspark/worker.py", line 174, in main
    process()
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/python/lib/pyspark.zip/pyspark/worker.py", line 169, in process
    serializer.dump_stream(func(split_index, iterator), outfile)
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/python/lib/pyspark.zip/pyspark/serializers.py", line 268, in dump_stream
    vs = list(itertools.islice(iterator, batch))
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/spark-2/python/lib/pyspark.zip/pyspark/rdd.py", line 833, in func
  File "/lustre/work/swanson/jdixon/CMS/CMS-Mining/SparkScripts/es_scatter.py", line 117, in hccReduce
    temp={'CpuEff' : np.append(accum["CpuEff"], \
KeyError: 'CpuEff'

	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:193)
	at org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)
	at org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
17/04/26 12:18:55 INFO Executor: Executor is trying to kill task 2.3 in stage 13.0 (TID 60)
17/04/26 12:18:55 WARN PythonRunner: Incomplete task interrupted: Attempting to kill Python Worker
17/04/26 12:18:55 INFO Executor: Executor is trying to kill task 4.3 in stage 13.0 (TID 61)
17/04/26 12:18:55 INFO Executor: Executor killed task 2.3 in stage 13.0 (TID 60)
17/04/26 12:18:55 INFO Executor: Executor killed task 4.3 in stage 13.0 (TID 61)
17/04/26 12:18:55 INFO CoarseGrainedExecutorBackend: Driver commanded a shutdown
17/04/26 12:18:55 ERROR CoarseGrainedExecutorBackend: RECEIVED SIGNAL TERM
tdown
